{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8914b649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from cellmaps_imagedownloader.runner import CellmapsImageDownloader\n",
    "from cellmaps_imagedownloader.runner import MultiProcessImageDownloader\n",
    "from cellmaps_imagedownloader.gene import ImageGeneNodeAttributeGenerator as IGen \n",
    "from cellmaps_imagedownloader.proteinatlas import ProteinAtlasReader, ProteinAtlasImageUrlReader, ImageDownloadTupleGenerator\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "#import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import json\n",
    "from collections import Counter\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94c19e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34m1.ppi_download\u001b[0m/                           \u001b[01;34mcellmaps_ppidownloader_outdir\u001b[0m/\r\n",
      "1.ppi_download.zip                        \u001b[01;34mdata\u001b[0m/\r\n",
      "\u001b[01;34m2.ppi_embedding_old\u001b[0m/                      demo1-Copy1.ipynb\r\n",
      "\u001b[01;34m3_new.coembedding_paclitaxel_old\u001b[0m/         demo1.ipynb\r\n",
      "\u001b[01;34m3_new.coembedding_untreated_old\u001b[0m/          \u001b[01;34membedding_bkp\u001b[0m/\r\n",
      "\u001b[01;34m5.2_new_hierarchy_old\u001b[0m/                    \u001b[01;34membedding_old\u001b[0m/\r\n",
      "\u001b[01;34m5.2_new_hierarchy_paclitaxel_old\u001b[0m/         \u001b[01;34mexamples\u001b[0m/\r\n",
      "\u001b[01;34m6.2_new_hierarchyeval_old\u001b[0m/                Untitled1.ipynb\r\n",
      "9606.protein.info.v12.0.txt.gz            Untitled2.ipynb\r\n",
      "9606.protein.links.detailed.v12.0.txt.gz  Untitled.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a34881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"data\"\n",
    "CHANNELS = [\"blue\", \"green\", \"red\", \"yellow\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "116ab2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_image_paths(base_path=BASE_PATH):\n",
    "    records = []\n",
    "    for treatment_folder in os.listdir(base_path):\n",
    "        treatment_path = os.path.join(base_path, treatment_folder)\n",
    "        if not os.path.isdir(treatment_path):\n",
    "            continue\n",
    "\n",
    "        treatment = treatment_folder.split(\"-\")[-1].lower()\n",
    "\n",
    "        image_dict = {}\n",
    "        for channel in CHANNELS:\n",
    "            channel_path = os.path.join(treatment_path, channel)\n",
    "            for img_path in glob(os.path.join(channel_path, \"*.jpg\")):\n",
    "                # Extract base ID (strip _blue, _red, etc.)\n",
    "                basename = os.path.basename(img_path).replace(f\"_{channel}.jpg\", \"\")\n",
    "                image_dict.setdefault(basename, {\"id\": basename, \"treatment\": treatment})\n",
    "                image_dict[basename][channel] = img_path\n",
    "\n",
    "        records.extend(image_dict.values())\n",
    "\n",
    "    return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3fd7e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rocrate_metadata_with_antibodies(base_path=BASE_PATH):\n",
    "    print('base path: ',base_path)\n",
    "    \n",
    "    metadata_records = []\n",
    "\n",
    "    for treatment_folder in os.listdir(base_path):\n",
    "        crate_path = os.path.join(base_path, treatment_folder, \"ro-crate-metadata.json\")\n",
    "        if not os.path.isfile(crate_path):\n",
    "            continue\n",
    "\n",
    "        with open(crate_path, \"r\") as f:\n",
    "            crate = json.load(f)\n",
    "\n",
    "        # --- Build antibody/stain index ---\n",
    "        antibody_index = {}\n",
    "        for entry in crate.get(\"@graph\", []):\n",
    "            if entry.get(\"@type\") == \"BioChemEntity\":\n",
    "                stain_id = entry[\"@id\"]\n",
    "                identifiers = entry.get(\"identifier\", [])\n",
    "                if isinstance(identifiers, dict):\n",
    "                    identifiers = [identifiers]\n",
    "\n",
    "                id_map = {i.get(\"name\"): i.get(\"value\") for i in identifiers}\n",
    "\n",
    "                antibody_index[stain_id] = {\n",
    "                    \"name\": entry.get(\"name\"),\n",
    "                    \"description\": entry.get(\"description\"),\n",
    "                    \"hpa_id\": id_map.get(\"HPA Antibody ID\"),\n",
    "                    \"ensembl\": id_map.get(\"ENSEMBL\"),\n",
    "                    \"uniprot\": id_map.get(\"Uniprot\"),\n",
    "                    \"pubchem\": id_map.get(\"PubChem\"),\n",
    "                    \"subcellular_location\": (\n",
    "                        entry.get(\"isLocatedInSubcellularLocation\", {}).get(\"name\")\n",
    "                        if isinstance(entry.get(\"isLocatedInSubcellularLocation\"), dict)\n",
    "                        else None\n",
    "                    )\n",
    "                }\n",
    "\n",
    "        # --- Process each dataset (image) entry ---\n",
    "        for entry in crate.get(\"@graph\", []):\n",
    "            if entry.get(\"@type\") != \"EVI:Dataset\":\n",
    "                continue\n",
    "\n",
    "            content_url = entry.get(\"contentUrl\", \"\")\n",
    "            filename = os.path.basename(content_url.replace(\"file://\", \"\")).strip(\"/\")\n",
    "            if not filename.endswith(\".jpg\"):\n",
    "                continue\n",
    "\n",
    "            base_id = filename.replace(\".jpg\", \"\").rsplit(\"_\", 1)[0]\n",
    "            channel = filename.replace(\".jpg\", \"\").rsplit(\"_\", 1)[-1].lower()\n",
    "\n",
    "            stain_ref = entry.get(\"usedStain\", {}).get(\"@id\", \"\")\n",
    "            stain_key = stain_ref.split(\"/\")[-1].replace(\"stain-\", \"\")\n",
    "            ab_meta = antibody_index.get(stain_ref, {})\n",
    "\n",
    "            metadata_records.append({\n",
    "                \"id\": base_id,\n",
    "                \"channel\": channel,\n",
    "                \"antibody_stain\": stain_key,\n",
    "                \"antibody_name\": ab_meta.get(\"name\"),\n",
    "                \"antibody_hpa_id\": ab_meta.get(\"hpa_id\"),\n",
    "                \"antibody_ensembl\": ab_meta.get(\"ensembl\"),\n",
    "                \"antibody_uniprot\": ab_meta.get(\"uniprot\"),\n",
    "                \"antibody_pubchem\": ab_meta.get(\"pubchem\"),\n",
    "                \"subcellular_location\": ab_meta.get(\"subcellular_location\"),\n",
    "                \"cell_line\": entry.get(\"usedCellLine\", {}).get(\"@id\", \"\").split(\"/\")[-1].replace(\"cell-line-\", \"\"),\n",
    "                \"treatment\": entry.get(\"usedTreatment\", {}).get(\"@id\", \"\").split(\"/\")[-1].replace(\"treatment-\", \"\"),\n",
    "                \"description\": entry.get(\"description\", \"\"),\n",
    "                \"filename\": filename\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(metadata_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cca03d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_lookup_ensembl_symbols(ensembl_ids, batch_size=1000):\n",
    "    \"\"\"\n",
    "    Look up gene symbols from Ensembl using batched POST requests.\n",
    "    Returns a dict {ensembl_id: gene_symbol}\n",
    "    \"\"\"\n",
    "    url = \"https://rest.ensembl.org/lookup/id\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    id_to_symbol = {}\n",
    "\n",
    "    for i in range(0, len(ensembl_ids), batch_size):\n",
    "        batch = ensembl_ids[i:i + batch_size]\n",
    "        payload = {\"ids\": batch}\n",
    "        try:\n",
    "            response = requests.post(url, headers=headers, json=payload)\n",
    "            if response.status_code == 200:\n",
    "                results = response.json()\n",
    "                for eid, info in results.items():\n",
    "                    id_to_symbol[eid] = info.get(\"display_name\", None)\n",
    "            else:\n",
    "                print(f\"⚠️ Error {response.status_code}: {response.text}\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Request failed for batch starting at {i}: {e}\")\n",
    "    \n",
    "    return id_to_symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b44704a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_multichannel_image(row):\n",
    "    \"\"\"\n",
    "    Loads a 4-channel immunofluorescence image from separate grayscale files.\n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): A row from df_images with keys: blue, green, red, yellow.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: H x W x 4 array with channels in the order [blue, green, red, yellow]\n",
    "    \"\"\"\n",
    "    img_channels = []\n",
    "    for ch in [\"blue\", \"green\", \"red\", \"yellow\"]:\n",
    "        path = row[ch]\n",
    "        img = Image.open(path).convert(\"L\")  # Load as 8-bit grayscale\n",
    "        img_array = np.array(img)\n",
    "        img_channels.append(img_array)\n",
    "\n",
    "    stacked = np.stack(img_channels, axis=-1)  # Shape: H x W x 4\n",
    "    return stacked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80415f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summary_report(df_merged, n_jobs=4):\n",
    "    print(\"🧬🔬 CM4AI Immunofluorescence Dataset Summary\\n\" + \"=\"*45, flush=True)\n",
    "\n",
    "    # 1. Number of treatments\n",
    "    n_treatments = df_merged[\"treatment\"].nunique()\n",
    "    print(f\"\\n💊 Number of treatments: {n_treatments}\", flush=True)\n",
    "    for cond, count in df_merged[\"treatment\"].value_counts().items():\n",
    "        print(f\"  - {cond}: {count} image-channel combinations\", flush=True)\n",
    "\n",
    "    # 2. Number of samples (unique image IDs) per treatment\n",
    "    print(\"\\n🧪 Number of unique samples per treatment:\", flush=True)\n",
    "    samples_per_treatment = (\n",
    "        df_merged[[\"id\", \"treatment\"]]\n",
    "        .drop_duplicates()\n",
    "        .groupby(\"treatment\")\n",
    "        .size()\n",
    "    )\n",
    "    for cond, count in samples_per_treatment.items():\n",
    "        print(f\"  - {cond}: {count} samples\", flush=True)\n",
    "\n",
    "    # 3. Image size distribution (parallelized)\n",
    "    print(\"\\n🖼 Image size distribution:\", flush=True)\n",
    "\n",
    "    # Reconstruct wide format for loading multichannel images\n",
    "    df_channels = df_merged[[\"id\", \"channel\", \"filepath\"]].drop_duplicates()\n",
    "    df_shapes = df_channels.pivot(index=\"id\", columns=\"channel\", values=\"filepath\").reset_index()\n",
    "    df_treatments = df_merged[[\"id\", \"treatment\"]].drop_duplicates()\n",
    "    df_shapes = df_shapes.merge(df_treatments, on=\"id\", how=\"left\")\n",
    "\n",
    "    def safe_load_shape(row):\n",
    "        try:\n",
    "            img = load_multichannel_image(row)\n",
    "            return img.shape[:2]\n",
    "        except Exception as e:\n",
    "            print(f\"  ⚠️ Error loading image for ID {row['id']}: {e}\", flush=True)\n",
    "            return None\n",
    "\n",
    "    print(\"🔄 Computing image shapes in parallel...\", flush=True)\n",
    "    shapes = Parallel(n_jobs=n_jobs, backend=\"threading\")(\n",
    "        delayed(safe_load_shape)(row) for _, row in tqdm(df_shapes.iterrows(), total=len(df_shapes))\n",
    "    )\n",
    "    df_shapes[\"shape\"] = shapes\n",
    "    shape_counts = Counter([s for s in shapes if s is not None])\n",
    "    for shape, count in shape_counts.items():\n",
    "        print(f\"  - {shape[0]}x{shape[1]}: {count} composite/multi-channel images\", flush=True)\n",
    "\n",
    "    # 4. Green channel antibody diversity\n",
    "    green_df = df_merged[df_merged[\"channel\"] == \"green\"]\n",
    "    unique_green = sorted(set(green_df[\"antibody_hpa_id\"].dropna().tolist()))\n",
    "    print(f\"\\n🟩 Number of unique antibodies in green channel (protein target): {len(unique_green)}\", flush=True)\n",
    "\n",
    "    # 5. Red, Blue, Yellow antibody/stain names with icons\n",
    "    print(\"\\n🎯 Antibodies/stains used in other channels:\", flush=True)\n",
    "\n",
    "    channel_icons = {\n",
    "        \"red\": \"🟥\",\n",
    "        \"blue\": \"🟦\",\n",
    "        \"yellow\": \"🟨\"\n",
    "    }\n",
    "\n",
    "    for ch in [\"red\", \"blue\", \"yellow\"]:\n",
    "        ch_df = df_merged[df_merged[\"channel\"] == ch]\n",
    "        unique_ab = sorted(set(\n",
    "            ch_df[\"antibody_hpa_id\"].dropna().tolist() +\n",
    "            ch_df[\"antibody_name\"].dropna().tolist()\n",
    "        ))\n",
    "        icon = channel_icons.get(ch, \"🔹\")\n",
    "        print(f\"\\n  {icon} {ch.upper()} channel antibodies/stains ({len(unique_ab)}):\", flush=True)\n",
    "        for ab in unique_ab:\n",
    "            print(f\"    - {ab}\", flush=True)\n",
    "\n",
    "    print(\"\\n✅ Summary complete.\\n\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5df82c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image_gene_node_attributes(df_merged, base_output_dir=\"data/raw\"):\n",
    "    # Filter to green channel (protein target)\n",
    "    df_green = df_merged[df_merged[\"channel\"] == \"green\"].copy()\n",
    "\n",
    "    # Normalize treatment label: \"control\" becomes \"untreated\"\n",
    "    df_green[\"treatment\"] = df_green[\"treatment\"].replace(\"control\", \"untreated\")\n",
    "\n",
    "    # Drop exact duplicates across key fields\n",
    "    df_green = df_green.drop_duplicates(subset=[\"id\", \"treatment\", \"antibody_hpa_id\", \"antibody_ensembl\"])\n",
    "\n",
    "    # Group by treatment\n",
    "    treatments = df_green[\"treatment\"].dropna().unique()\n",
    "\n",
    "    for treatment in treatments:\n",
    "        df_t = df_green[df_green[\"treatment\"] == treatment]\n",
    "\n",
    "        df_out = pd.DataFrame({\n",
    "            \"name\": df_t[\"antibody_name\"],\n",
    "            \"represents\": \"ensembl:\" + df_t[\"antibody_ensembl\"].fillna(\"\"),\n",
    "            \"ambiguous\": df_t[\"antibody_hpa_id\"],\n",
    "            \"antibody\": df_t[\"antibody_hpa_id\"],\n",
    "            \"filename\": df_t[\"id\"].astype(str) + \"_\",\n",
    "            \"imageurl\": \"no image url found\"\n",
    "        })\n",
    "\n",
    "        unique_ensembl_ids = (\n",
    "            df_out[\"represents\"]\n",
    "            .dropna()\n",
    "            .str.replace(\"ensembl:\", \"\", regex=False)\n",
    "            .loc[lambda s: s.str.match(r\"ENSG\\d+\")]  # keep only valid Ensembl Gene IDs\n",
    "            .unique()\n",
    "            .tolist()\n",
    "        )\n",
    "\n",
    "        ensembl_to_name = batch_lookup_ensembl_symbols(unique_ensembl_ids)\n",
    "\n",
    "        df_out[\"name\"] = (\n",
    "            df_out[\"represents\"]\n",
    "            .str.replace(\"ensembl:\", \"\", regex=False)\n",
    "            .map(ensembl_to_name)\n",
    "        )\n",
    "\n",
    "        df_out[\"name\"] = df_out[\"name\"].fillna(\"NEGATIVE\")\n",
    "\n",
    "        # Save to the appropriate treatment folder\n",
    "        treatment_folder = os.path.join(base_output_dir, treatment)\n",
    "        os.makedirs(treatment_folder, exist_ok=True)\n",
    "\n",
    "        out_path = os.path.join(treatment_folder, \"1_image_gene_node_attributes.tsv\")\n",
    "        df_out.to_csv(out_path, sep=\"\\t\", index=False)\n",
    "\n",
    "        print(f\"✅ Saved: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89010645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>treatment</th>\n",
       "      <th>blue</th>\n",
       "      <th>green</th>\n",
       "      <th>red</th>\n",
       "      <th>yellow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B2AI_5_untreated_D5_R1_z01</td>\n",
       "      <td>untreated</td>\n",
       "      <td>data/untreated/blue/B2AI_5_untreated_D5_R1_z01...</td>\n",
       "      <td>data/untreated/green/B2AI_5_untreated_D5_R1_z0...</td>\n",
       "      <td>data/untreated/red/B2AI_5_untreated_D5_R1_z01_...</td>\n",
       "      <td>data/untreated/yellow/B2AI_5_untreated_D5_R1_z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B2AI_2_untreated_D7_R11_z00</td>\n",
       "      <td>untreated</td>\n",
       "      <td>data/untreated/blue/B2AI_2_untreated_D7_R11_z0...</td>\n",
       "      <td>data/untreated/green/B2AI_2_untreated_D7_R11_z...</td>\n",
       "      <td>data/untreated/red/B2AI_2_untreated_D7_R11_z00...</td>\n",
       "      <td>data/untreated/yellow/B2AI_2_untreated_D7_R11_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B2AI_1_untreated_H11_R16_z02</td>\n",
       "      <td>untreated</td>\n",
       "      <td>data/untreated/blue/B2AI_1_untreated_H11_R16_z...</td>\n",
       "      <td>data/untreated/green/B2AI_1_untreated_H11_R16_...</td>\n",
       "      <td>data/untreated/red/B2AI_1_untreated_H11_R16_z0...</td>\n",
       "      <td>data/untreated/yellow/B2AI_1_untreated_H11_R16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B2AI_2_untreated_F9_R5_z01</td>\n",
       "      <td>untreated</td>\n",
       "      <td>data/untreated/blue/B2AI_2_untreated_F9_R5_z01...</td>\n",
       "      <td>data/untreated/green/B2AI_2_untreated_F9_R5_z0...</td>\n",
       "      <td>data/untreated/red/B2AI_2_untreated_F9_R5_z01_...</td>\n",
       "      <td>data/untreated/yellow/B2AI_2_untreated_F9_R5_z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B2AI_2_untreated_H9_R6_z01</td>\n",
       "      <td>untreated</td>\n",
       "      <td>data/untreated/blue/B2AI_2_untreated_H9_R6_z01...</td>\n",
       "      <td>data/untreated/green/B2AI_2_untreated_H9_R6_z0...</td>\n",
       "      <td>data/untreated/red/B2AI_2_untreated_H9_R6_z01_...</td>\n",
       "      <td>data/untreated/yellow/B2AI_2_untreated_H9_R6_z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12855</th>\n",
       "      <td>B2AI_1_Paclitaxel_G5_R8_z01</td>\n",
       "      <td>paclitaxel</td>\n",
       "      <td>data/paclitaxel/blue/B2AI_1_Paclitaxel_G5_R8_z...</td>\n",
       "      <td>data/paclitaxel/green/B2AI_1_Paclitaxel_G5_R8_...</td>\n",
       "      <td>data/paclitaxel/red/B2AI_1_Paclitaxel_G5_R8_z0...</td>\n",
       "      <td>data/paclitaxel/yellow/B2AI_1_Paclitaxel_G5_R8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12856</th>\n",
       "      <td>B2AI_3_Paclitaxel_B11_R3_z02</td>\n",
       "      <td>paclitaxel</td>\n",
       "      <td>data/paclitaxel/blue/B2AI_3_Paclitaxel_B11_R3_...</td>\n",
       "      <td>data/paclitaxel/green/B2AI_3_Paclitaxel_B11_R3...</td>\n",
       "      <td>data/paclitaxel/red/B2AI_3_Paclitaxel_B11_R3_z...</td>\n",
       "      <td>data/paclitaxel/yellow/B2AI_3_Paclitaxel_B11_R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12857</th>\n",
       "      <td>B2AI_5_Paclitaxel_H4_R26_z01</td>\n",
       "      <td>paclitaxel</td>\n",
       "      <td>data/paclitaxel/blue/B2AI_5_Paclitaxel_H4_R26_...</td>\n",
       "      <td>data/paclitaxel/green/B2AI_5_Paclitaxel_H4_R26...</td>\n",
       "      <td>data/paclitaxel/red/B2AI_5_Paclitaxel_H4_R26_z...</td>\n",
       "      <td>data/paclitaxel/yellow/B2AI_5_Paclitaxel_H4_R2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12858</th>\n",
       "      <td>B2AI_2_Paclitaxel_C3_R2_z01</td>\n",
       "      <td>paclitaxel</td>\n",
       "      <td>data/paclitaxel/blue/B2AI_2_Paclitaxel_C3_R2_z...</td>\n",
       "      <td>data/paclitaxel/green/B2AI_2_Paclitaxel_C3_R2_...</td>\n",
       "      <td>data/paclitaxel/red/B2AI_2_Paclitaxel_C3_R2_z0...</td>\n",
       "      <td>data/paclitaxel/yellow/B2AI_2_Paclitaxel_C3_R2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12859</th>\n",
       "      <td>B2AI_5_Paclitaxel_B6_R11_z02</td>\n",
       "      <td>paclitaxel</td>\n",
       "      <td>data/paclitaxel/blue/B2AI_5_Paclitaxel_B6_R11_...</td>\n",
       "      <td>data/paclitaxel/green/B2AI_5_Paclitaxel_B6_R11...</td>\n",
       "      <td>data/paclitaxel/red/B2AI_5_Paclitaxel_B6_R11_z...</td>\n",
       "      <td>data/paclitaxel/yellow/B2AI_5_Paclitaxel_B6_R1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12860 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id   treatment  \\\n",
       "0        B2AI_5_untreated_D5_R1_z01   untreated   \n",
       "1       B2AI_2_untreated_D7_R11_z00   untreated   \n",
       "2      B2AI_1_untreated_H11_R16_z02   untreated   \n",
       "3        B2AI_2_untreated_F9_R5_z01   untreated   \n",
       "4        B2AI_2_untreated_H9_R6_z01   untreated   \n",
       "...                             ...         ...   \n",
       "12855   B2AI_1_Paclitaxel_G5_R8_z01  paclitaxel   \n",
       "12856  B2AI_3_Paclitaxel_B11_R3_z02  paclitaxel   \n",
       "12857  B2AI_5_Paclitaxel_H4_R26_z01  paclitaxel   \n",
       "12858   B2AI_2_Paclitaxel_C3_R2_z01  paclitaxel   \n",
       "12859  B2AI_5_Paclitaxel_B6_R11_z02  paclitaxel   \n",
       "\n",
       "                                                    blue  \\\n",
       "0      data/untreated/blue/B2AI_5_untreated_D5_R1_z01...   \n",
       "1      data/untreated/blue/B2AI_2_untreated_D7_R11_z0...   \n",
       "2      data/untreated/blue/B2AI_1_untreated_H11_R16_z...   \n",
       "3      data/untreated/blue/B2AI_2_untreated_F9_R5_z01...   \n",
       "4      data/untreated/blue/B2AI_2_untreated_H9_R6_z01...   \n",
       "...                                                  ...   \n",
       "12855  data/paclitaxel/blue/B2AI_1_Paclitaxel_G5_R8_z...   \n",
       "12856  data/paclitaxel/blue/B2AI_3_Paclitaxel_B11_R3_...   \n",
       "12857  data/paclitaxel/blue/B2AI_5_Paclitaxel_H4_R26_...   \n",
       "12858  data/paclitaxel/blue/B2AI_2_Paclitaxel_C3_R2_z...   \n",
       "12859  data/paclitaxel/blue/B2AI_5_Paclitaxel_B6_R11_...   \n",
       "\n",
       "                                                   green  \\\n",
       "0      data/untreated/green/B2AI_5_untreated_D5_R1_z0...   \n",
       "1      data/untreated/green/B2AI_2_untreated_D7_R11_z...   \n",
       "2      data/untreated/green/B2AI_1_untreated_H11_R16_...   \n",
       "3      data/untreated/green/B2AI_2_untreated_F9_R5_z0...   \n",
       "4      data/untreated/green/B2AI_2_untreated_H9_R6_z0...   \n",
       "...                                                  ...   \n",
       "12855  data/paclitaxel/green/B2AI_1_Paclitaxel_G5_R8_...   \n",
       "12856  data/paclitaxel/green/B2AI_3_Paclitaxel_B11_R3...   \n",
       "12857  data/paclitaxel/green/B2AI_5_Paclitaxel_H4_R26...   \n",
       "12858  data/paclitaxel/green/B2AI_2_Paclitaxel_C3_R2_...   \n",
       "12859  data/paclitaxel/green/B2AI_5_Paclitaxel_B6_R11...   \n",
       "\n",
       "                                                     red  \\\n",
       "0      data/untreated/red/B2AI_5_untreated_D5_R1_z01_...   \n",
       "1      data/untreated/red/B2AI_2_untreated_D7_R11_z00...   \n",
       "2      data/untreated/red/B2AI_1_untreated_H11_R16_z0...   \n",
       "3      data/untreated/red/B2AI_2_untreated_F9_R5_z01_...   \n",
       "4      data/untreated/red/B2AI_2_untreated_H9_R6_z01_...   \n",
       "...                                                  ...   \n",
       "12855  data/paclitaxel/red/B2AI_1_Paclitaxel_G5_R8_z0...   \n",
       "12856  data/paclitaxel/red/B2AI_3_Paclitaxel_B11_R3_z...   \n",
       "12857  data/paclitaxel/red/B2AI_5_Paclitaxel_H4_R26_z...   \n",
       "12858  data/paclitaxel/red/B2AI_2_Paclitaxel_C3_R2_z0...   \n",
       "12859  data/paclitaxel/red/B2AI_5_Paclitaxel_B6_R11_z...   \n",
       "\n",
       "                                                  yellow  \n",
       "0      data/untreated/yellow/B2AI_5_untreated_D5_R1_z...  \n",
       "1      data/untreated/yellow/B2AI_2_untreated_D7_R11_...  \n",
       "2      data/untreated/yellow/B2AI_1_untreated_H11_R16...  \n",
       "3      data/untreated/yellow/B2AI_2_untreated_F9_R5_z...  \n",
       "4      data/untreated/yellow/B2AI_2_untreated_H9_R6_z...  \n",
       "...                                                  ...  \n",
       "12855  data/paclitaxel/yellow/B2AI_1_Paclitaxel_G5_R8...  \n",
       "12856  data/paclitaxel/yellow/B2AI_3_Paclitaxel_B11_R...  \n",
       "12857  data/paclitaxel/yellow/B2AI_5_Paclitaxel_H4_R2...  \n",
       "12858  data/paclitaxel/yellow/B2AI_2_Paclitaxel_C3_R2...  \n",
       "12859  data/paclitaxel/yellow/B2AI_5_Paclitaxel_B6_R1...  \n",
       "\n",
       "[12860 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_images = collect_image_paths()\n",
    "df_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee03447a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>treatment</th>\n",
       "      <th>blue</th>\n",
       "      <th>green</th>\n",
       "      <th>red</th>\n",
       "      <th>yellow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>B2AI_3_untreated_C2_R3_z01</td>\n",
       "      <td>untreated</td>\n",
       "      <td>data/untreated/blue/B2AI_3_untreated_C2_R3_z01_blue.jpg</td>\n",
       "      <td>data/untreated/green/B2AI_3_untreated_C2_R3_z01_green.jpg</td>\n",
       "      <td>data/untreated/red/B2AI_3_untreated_C2_R3_z01_red.jpg</td>\n",
       "      <td>data/untreated/yellow/B2AI_3_untreated_C2_R3_z01_yellow.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9353</th>\n",
       "      <td>B2AI_3_untreated_C2_R3_z01</td>\n",
       "      <td>paclitaxel</td>\n",
       "      <td>data/paclitaxel/blue/B2AI_3_untreated_C2_R3_z01_blue.jpg</td>\n",
       "      <td>data/paclitaxel/green/B2AI_3_untreated_C2_R3_z01_green.jpg</td>\n",
       "      <td>data/paclitaxel/red/B2AI_3_untreated_C2_R3_z01_red.jpg</td>\n",
       "      <td>data/paclitaxel/yellow/B2AI_3_untreated_C2_R3_z01_yellow.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id   treatment  \\\n",
       "824   B2AI_3_untreated_C2_R3_z01   untreated   \n",
       "9353  B2AI_3_untreated_C2_R3_z01  paclitaxel   \n",
       "\n",
       "                                                          blue  \\\n",
       "824    data/untreated/blue/B2AI_3_untreated_C2_R3_z01_blue.jpg   \n",
       "9353  data/paclitaxel/blue/B2AI_3_untreated_C2_R3_z01_blue.jpg   \n",
       "\n",
       "                                                           green  \\\n",
       "824    data/untreated/green/B2AI_3_untreated_C2_R3_z01_green.jpg   \n",
       "9353  data/paclitaxel/green/B2AI_3_untreated_C2_R3_z01_green.jpg   \n",
       "\n",
       "                                                         red  \\\n",
       "824    data/untreated/red/B2AI_3_untreated_C2_R3_z01_red.jpg   \n",
       "9353  data/paclitaxel/red/B2AI_3_untreated_C2_R3_z01_red.jpg   \n",
       "\n",
       "                                                            yellow  \n",
       "824    data/untreated/yellow/B2AI_3_untreated_C2_R3_z01_yellow.jpg  \n",
       "9353  data/paclitaxel/yellow/B2AI_3_untreated_C2_R3_z01_yellow.jpg  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_colwidth', None):\n",
    "    display(df_images[df_images.duplicated(subset=\"id\", keep=False)].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f49c7978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base path:  data\n"
     ]
    }
   ],
   "source": [
    "df_meta = load_rocrate_metadata_with_antibodies()\n",
    "df_images_melted = df_images.melt(\n",
    "    id_vars=[\"id\"],  # remove \"treatment\" here\n",
    "    value_vars=[\"blue\", \"green\", \"red\", \"yellow\"],\n",
    "    var_name=\"channel\",\n",
    "    value_name=\"filepath\"\n",
    ")\n",
    "\n",
    "df_merged = df_images_melted.merge(df_meta, on=[\"id\", \"channel\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de729d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: data/untreated/1_image_gene_node_attributes.tsv\n",
      "✅ Saved: data/vorinostat/1_image_gene_node_attributes.tsv\n",
      "✅ Saved: data/paclitaxel/1_image_gene_node_attributes.tsv\n"
     ]
    }
   ],
   "source": [
    "save_image_gene_node_attributes(df_merged, base_output_dir=BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3fed3443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# from cellmaps_image_embedding.runner import DensenetEmbeddingGenerator\n",
    "# from cellmaps_image_embedding.runner import CellmapsImageEmbedder\n",
    "\n",
    "# input_base_path = \"data\"\n",
    "# image_interim_base_path = \"pipeline_images\"\n",
    "# embedding_base_path = \"embedding_old2\"\n",
    "\n",
    "# for treatment_folder in os.listdir(input_base_path):\n",
    "#     input_path = os.path.join(input_base_path, treatment_folder)\n",
    "#     if not os.path.isdir(input_path):\n",
    "#         continue\n",
    "#     manifest_path = os.path.join(input_path, \"manifest.csv\")\n",
    "#     image_interim_path = os.path.join(image_interim_base_path, treatment_folder)\n",
    "#     embedding_path = os.path.join(embedding_base_path, treatment_folder)\n",
    "\n",
    "#     gen = DensenetEmbeddingGenerator(\n",
    "#         input_path,\n",
    "#         outdir=embedding_path,\n",
    "#         model_path=\"https://github.com/CellProfiling/densenet/releases/download/v0.1.0/external_crop512_focal_slov_hardlog_class_densenet121_dropout_i768_aug2_5folds_fold0_final.pth\",\n",
    "#         fold=1\n",
    "#     )\n",
    "#     embedder = CellmapsImageEmbedder(\n",
    "#         outdir=embedding_path,\n",
    "#         inputdir=input_path,\n",
    "#         embedding_generator=gen,\n",
    "#         name=f\"{treatment_folder} IF Embedding\",\n",
    "#         organization_name=\"CM4AI\",\n",
    "#         project_name=\"CM4AI IF Embedding Tutorial\"\n",
    "#     )\n",
    "#     embedder.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1441f5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean values saved to: embedding_old/vorinostat/gene_means.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load TSV file\n",
    "input_file = \"embedding_old/vorinostat/image_emd.tsv\"   # replace with your filename\n",
    "df = pd.read_csv(input_file, sep=\"\\t\")\n",
    "\n",
    "# Step 2: Compute mean per gene (assumes first column is \"id\" or \"Gene\")\n",
    "mean_df = df.groupby(df.columns[0]).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Step 3: Save to a new file\n",
    "output_file = \"embedding_old/vorinostat/gene_means.tsv\"\n",
    "mean_df.to_csv(output_file, sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"Mean values saved to:\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3c24b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -r data/.ipynb_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c35efe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellmaps_ppi_embedding.runner import Node2VecEmbeddingGenerator\n",
    "from cellmaps_ppi_embedding.runner import CellMapsPPIEmbedder\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a32be617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba27b8a1b874dde94a782d4248e31b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/1362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 3): 100%|██████████| 1/1 [00:04<00:00,  4.75s/it]\n",
      "Generating walks (CPU: 4): 100%|██████████| 1/1 [00:04<00:00,  4.79s/it]\n",
      "Generating walks (CPU: 5): 100%|██████████| 1/1 [00:04<00:00,  4.78s/it]\n",
      "Generating walks (CPU: 7): 100%|██████████| 1/1 [00:04<00:00,  4.79s/it]\n",
      "Generating walks (CPU: 6): 100%|██████████| 1/1 [00:04<00:00,  4.78s/it]\n",
      "Generating walks (CPU: 8): 100%|██████████| 1/1 [00:04<00:00,  4.82s/it]\n",
      "Generating walks (CPU: 1): 100%|██████████| 2/2 [00:09<00:00,  4.58s/it]\n",
      "Generating walks (CPU: 2): 100%|██████████| 2/2 [00:09<00:00,  4.59s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputdir = '1.ppi_download'\n",
    "outdir = '2.ppi_embedding'\n",
    "gen = Node2VecEmbeddingGenerator(nx_network=nx.read_edgelist(CellMapsPPIEmbedder.get_apms_edgelist_file(inputdir),\n",
    "                                                             delimiter='\\t'))\n",
    "\n",
    "x =CellMapsPPIEmbedder(outdir=outdir,\n",
    "                       embedding_generator=gen,\n",
    "                      inputdir=inputdir)\n",
    "x.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b98aab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving embedding: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.15346574783325195 seconds\n",
      "Jaccard graph constructed in 0.9450294971466064 seconds\n",
      "Wrote graph to binary file in 0.0014743804931640625 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.666489\n",
      "After 3 runs, maximum modularity is Q = 0.667549\n",
      "After 23 runs, maximum modularity is Q = 0.668984\n",
      "Louvain completed 43 runs in 0.6367402076721191 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.6732378005981445 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.014770030975341797 seconds\n",
      "Jaccard graph constructed in 0.9313602447509766 seconds\n",
      "Wrote graph to binary file in 0.0016448497772216797 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.655149\n",
      "After 6 runs, maximum modularity is Q = 0.660435\n",
      "After 7 runs, maximum modularity is Q = 0.662616\n",
      "Louvain completed 27 runs in 0.12122869491577148 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.011718988418579 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.03494906425476074 seconds\n",
      "Jaccard graph constructed in 1.1116304397583008 seconds\n",
      "Wrote graph to binary file in 0.0021598339080810547 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.49872\n",
      "Louvain completed 21 runs in 0.09859299659729004 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.3378236293792725 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.016051769256591797 seconds\n",
      "Jaccard graph constructed in 1.0874760150909424 seconds\n",
      "Wrote graph to binary file in 0.0025320053100585938 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.664589\n",
      "After 11 runs, maximum modularity is Q = 0.666185\n",
      "Louvain completed 31 runs in 0.11734914779663086 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.362859010696411 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.014959335327148438 seconds\n",
      "Jaccard graph constructed in 1.0931086540222168 seconds\n",
      "Wrote graph to binary file in 0.0015268325805664062 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.659992\n",
      "Louvain completed 21 runs in 0.0797429084777832 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.265611410140991 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.01567840576171875 seconds\n",
      "Jaccard graph constructed in 1.1449410915374756 seconds\n",
      "Wrote graph to binary file in 0.0026929378509521484 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.745919\n",
      "Louvain completed 21 runs in 0.07718229293823242 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.3540024757385254 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.01479196548461914 seconds\n",
      "Jaccard graph constructed in 1.0910155773162842 seconds\n",
      "Wrote graph to binary file in 0.0014221668243408203 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.671324\n",
      "Louvain completed 21 runs in 0.07673883438110352 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.2648749351501465 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.01584625244140625 seconds\n",
      "Jaccard graph constructed in 1.1718204021453857 seconds\n",
      "Wrote graph to binary file in 0.002061605453491211 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.761007\n",
      "Louvain completed 21 runs in 0.07631254196166992 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.3781213760375977 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving embedding: 97it [00:55,  1.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell map paclitaxel\n",
    "\n",
    "from cellmaps_coembedding.runner import MuseCoEmbeddingGenerator\n",
    "from cellmaps_coembedding.runner import CellmapsCoEmbedder\n",
    "\n",
    "ppi_embeddingdir = '2.ppi_embedding'\n",
    "image_embeddingdir = 'embedding_old/paclitaxel'\n",
    "outdir = '3_old.coembedding_paclitaxel'\n",
    "gen = MuseCoEmbeddingGenerator(ppi_embeddingdir=ppi_embeddingdir,\n",
    "                               image_embeddingdir=image_embeddingdir,\n",
    "                               outdir=os.path.abspath(outdir))\n",
    "\n",
    "x = CellmapsCoEmbedder(outdir=outdir,\n",
    "                      inputdirs=[ppi_embeddingdir, image_embeddingdir],\n",
    "                      embedding_generator=gen)\n",
    "x.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86d79d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "input_file = \"embedding_old/paclitaxel/image_emd.tsv\"\n",
    "# Store embeddings per gene\n",
    "data = defaultdict(list)\n",
    "# Read the original file\n",
    "with open(input_file, \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    header = next(reader) # store header\n",
    "    for row in reader:\n",
    "        gene_id = row[0]\n",
    "        embedding = list(map(float, row[1:]))\n",
    "        data[gene_id].append(embedding)\n",
    "# Compute mean and overwrite the same file\n",
    "with open(input_file, \"w\", newline='') as out:\n",
    "    writer = csv.writer(out, delimiter='\\t')\n",
    "    writer.writerow([\"id\"] + header[1:]) # write header back\n",
    "    for gene_id, vectors in data.items():\n",
    "        arr = np.array(vectors)\n",
    "        mean_vector = np.mean(arr, axis=0)\n",
    "        writer.writerow([gene_id] + mean_vector.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b67cc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique genes: 461\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "input_file = \"embedding_old/paclitaxel/image_emd.tsv\"\n",
    "unique_genes = set()\n",
    "with open(input_file, \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    next(reader) # skip header\n",
    "    for row in reader:\n",
    "        gene_id = row[0]\n",
    "        unique_genes.add(gene_id)\n",
    "print(f\"Number of unique genes: {len(unique_genes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9eb00f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating hierarchy: 15it [00:00, 41.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/hnguye24/.conda/envs/yolo7/lib/python3.10/site-packages/cellmaps_generate_hierarchy/runner.py:623: UserWarning: Layout disabled due to incompatibilities with HCX format\n",
      "  warnings.warn(\"Layout disabled due to incompatibilities with HCX format\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cellmaps_generate_hierarchy.ppi import CosineSimilarityPPIGenerator\n",
    "from cellmaps_generate_hierarchy.hierarchy import CDAPSHiDeFHierarchyGenerator\n",
    "from cellmaps_generate_hierarchy.maturehierarchy import HiDeFHierarchyRefiner\n",
    "from cellmaps_generate_hierarchy.hcx import HCXFromCDAPSCXHierarchy\n",
    "from cellmaps_generate_hierarchy.runner import CellmapsGenerateHierarchy\n",
    "\n",
    "inputdir = '3_old.coembedding_paclitaxel'\n",
    "outdir = '5.2_old_hierarchy_paclitaxel'\n",
    "ppigen = CosineSimilarityPPIGenerator(embeddingdirs=[inputdir])\n",
    "\n",
    "refiner = HiDeFHierarchyRefiner()\n",
    "\n",
    "converter = HCXFromCDAPSCXHierarchy()\n",
    "\n",
    "hiergen = CDAPSHiDeFHierarchyGenerator(refiner=refiner,\n",
    "                                       hcxconverter=converter)\n",
    "\n",
    "x = CellmapsGenerateHierarchy(outdir=outdir,\n",
    "                              inputdirs=inputdir,\n",
    "                              ppigen=ppigen,\n",
    "                              hiergen=hiergen)\n",
    "x.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61e4c1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving embedding: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.027947425842285156 seconds\n",
      "Jaccard graph constructed in 1.1675999164581299 seconds\n",
      "Wrote graph to binary file in 0.0016143321990966797 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.666489\n",
      "After 6 runs, maximum modularity is Q = 0.668028\n",
      "Louvain completed 26 runs in 0.1322641372680664 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.5178775787353516 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.016335487365722656 seconds\n",
      "Jaccard graph constructed in 1.2155492305755615 seconds\n",
      "Wrote graph to binary file in 0.0014913082122802734 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.688349\n",
      "Louvain completed 21 runs in 0.07727336883544922 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.4983835220336914 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.023468732833862305 seconds\n",
      "Jaccard graph constructed in 1.1865167617797852 seconds\n",
      "Wrote graph to binary file in 0.0013458728790283203 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.523296\n",
      "After 5 runs, maximum modularity is Q = 0.525691\n",
      "Louvain completed 25 runs in 0.0992729663848877 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.4670746326446533 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.01594996452331543 seconds\n",
      "Jaccard graph constructed in 1.197991132736206 seconds\n",
      "Wrote graph to binary file in 0.0014653205871582031 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.697103\n",
      "Louvain completed 21 runs in 0.07750749588012695 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.455111503601074 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.018249988555908203 seconds\n",
      "Jaccard graph constructed in 1.20184326171875 seconds\n",
      "Wrote graph to binary file in 0.0015063285827636719 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.650474\n",
      "After 2 runs, maximum modularity is Q = 0.66258\n",
      "Louvain completed 22 runs in 0.09110403060913086 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.4888484477996826 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.015601158142089844 seconds\n",
      "Jaccard graph constructed in 1.168691635131836 seconds\n",
      "Wrote graph to binary file in 0.0015594959259033203 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.753405\n",
      "After 3 runs, maximum modularity is Q = 0.764737\n",
      "Louvain completed 23 runs in 0.09695696830749512 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.481640100479126 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.024060964584350586 seconds\n",
      "Jaccard graph constructed in 1.2164692878723145 seconds\n",
      "Wrote graph to binary file in 0.0023643970489501953 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.661215\n",
      "After 9 runs, maximum modularity is Q = 0.662461\n",
      "Louvain completed 29 runs in 0.11072397232055664 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.516010046005249 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.07103776931762695 seconds\n",
      "Jaccard graph constructed in 1.1859369277954102 seconds\n",
      "Wrote graph to binary file in 0.002457141876220703 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.76911\n",
      "Louvain completed 21 runs in 0.07798099517822266 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.5151660442352295 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving embedding: 97it [00:29,  3.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell map untreated\n",
    "\n",
    "from cellmaps_coembedding.runner import MuseCoEmbeddingGenerator\n",
    "from cellmaps_coembedding.runner import CellmapsCoEmbedder\n",
    "\n",
    "ppi_embeddingdir = '2.ppi_embedding'\n",
    "image_embeddingdir = 'embedding_old/untreated'\n",
    "outdir = '3_old.coembedding_untreated'\n",
    "gen = MuseCoEmbeddingGenerator(ppi_embeddingdir=ppi_embeddingdir,\n",
    "                               image_embeddingdir=image_embeddingdir,\n",
    "                               outdir=os.path.abspath(outdir))\n",
    "\n",
    "x = CellmapsCoEmbedder(outdir=outdir,\n",
    "                      inputdirs=[ppi_embeddingdir, image_embeddingdir],\n",
    "                      embedding_generator=gen)\n",
    "x.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a94fac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "input_file = \"embedding_old/untreated/image_emd.tsv\"\n",
    "# Store embeddings per gene\n",
    "data = defaultdict(list)\n",
    "# Read the original file\n",
    "with open(input_file, \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    header = next(reader) # store header\n",
    "    for row in reader:\n",
    "        gene_id = row[0]\n",
    "        embedding = list(map(float, row[1:]))\n",
    "        data[gene_id].append(embedding)\n",
    "# Compute mean and overwrite the same file\n",
    "with open(input_file, \"w\", newline='') as out:\n",
    "    writer = csv.writer(out, delimiter='\\t')\n",
    "    writer.writerow([\"id\"] + header[1:]) # write header back\n",
    "    for gene_id, vectors in data.items():\n",
    "        arr = np.array(vectors)\n",
    "        mean_vector = np.mean(arr, axis=0)\n",
    "        writer.writerow([gene_id] + mean_vector.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e69678c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique genes: 461\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "input_file = \"embedding_old/untreated/image_emd.tsv\"\n",
    "unique_genes = set()\n",
    "with open(input_file, \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    next(reader) # skip header\n",
    "    for row in reader:\n",
    "        gene_id = row[0]\n",
    "        unique_genes.add(gene_id)\n",
    "print(f\"Number of unique genes: {len(unique_genes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d8887ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating hierarchy: 15it [00:00, 82.56it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hnguye24/.conda/envs/yolo7/lib/python3.10/site-packages/cellmaps_generate_hierarchy/runner.py:623: UserWarning: Layout disabled due to incompatibilities with HCX format\n",
      "  warnings.warn(\"Layout disabled due to incompatibilities with HCX format\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cellmaps_generate_hierarchy.ppi import CosineSimilarityPPIGenerator\n",
    "from cellmaps_generate_hierarchy.hierarchy import CDAPSHiDeFHierarchyGenerator\n",
    "from cellmaps_generate_hierarchy.maturehierarchy import HiDeFHierarchyRefiner\n",
    "from cellmaps_generate_hierarchy.hcx import HCXFromCDAPSCXHierarchy\n",
    "from cellmaps_generate_hierarchy.runner import CellmapsGenerateHierarchy\n",
    "\n",
    "inputdir = '3_old.coembedding_untreated'\n",
    "outdir = '5.2_old_hierarchy_untreated'\n",
    "ppigen = CosineSimilarityPPIGenerator(embeddingdirs=[inputdir])\n",
    "\n",
    "refiner = HiDeFHierarchyRefiner()\n",
    "\n",
    "converter = HCXFromCDAPSCXHierarchy()\n",
    "\n",
    "hiergen = CDAPSHiDeFHierarchyGenerator(refiner=refiner,\n",
    "                                       hcxconverter=converter)\n",
    "\n",
    "x = CellmapsGenerateHierarchy(outdir=outdir,\n",
    "                              inputdirs=inputdir,\n",
    "                              ppigen=ppigen,\n",
    "                              hiergen=hiergen)\n",
    "x.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "82d164eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent network UUID is e4f88557-9024-11f0-a218-005056ae3c32 and its URL in NDEx is https://www.ndexbio.org/viewer/networks/e4f88557-9024-11f0-a218-005056ae3c32\n",
      "Hierarchy network UUID is e513fc99-9024-11f0-a218-005056ae3c32 and its URL in NDEx is https://www.ndexbio.org/viewer/networks/e513fc99-9024-11f0-a218-005056ae3c32\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ndex2\n",
    "from ndex2.cx2 import RawCX2NetworkFactory\n",
    "from cellmaps_generate_hierarchy.ndexupload import NDExHierarchyUploader\n",
    "\n",
    "#Specify NDEx server\n",
    "ndexserver = 'public.ndexbio.org'\n",
    "ndexuser = ''\n",
    "ndexpassword = ''\n",
    "    \n",
    "# Specify paths to hierarchy and its parent (you can find example files in examples directory in cellmaps_generate_hierarchy_repo)\n",
    "hierarchy_path = './5.2_old_hierarchy_untreated/hierarchy.cx2'\n",
    "parent_network_path = './5.2_old_hierarchy_untreated/hierarchy_parent.cx2'\n",
    "\n",
    "# Load the hierarchy and parent network CX2 files into network objects\n",
    "factory = RawCX2NetworkFactory()\n",
    "hierarchy_network = factory.get_cx2network(hierarchy_path)\n",
    "parent_network = factory.get_cx2network(parent_network_path)\n",
    "\n",
    "# Initialize NDExHierarchyUploader with the specified NDEx server and credentials\n",
    "uploader = NDExHierarchyUploader(ndexserver, ndexuser, ndexpassword, visibility=True)\n",
    "\n",
    "# Upload the hierarchy and parent network to NDEx\n",
    "parent_uuid, parenturl, hierarchy_uuid, hierarchyurl = uploader.save_hierarchy_and_parent_network(hierarchy_network, parent_network)\n",
    "\n",
    "print(f\"Parent network UUID is {parent_uuid} and its URL in NDEx is {parenturl}\")\n",
    "print(f\"Hierarchy network UUID is {hierarchy_uuid} and its URL in NDEx is {hierarchyurl}\")\n",
    "\n",
    "# # Another option is to just specify the directory where the files are placed\n",
    "# _, _, _, hierarchyurl = uploader.upload_hierary_and_parent_network_from_files('./examples/')\n",
    "# print(f'Hierarchy uploaded. To view the hierarchy, paste this URL in your browser: {hierarchyurl}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d6403f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ndex2\n",
    "from ndex2.cx2 import RawCX2NetworkFactory\n",
    "from cellmaps_generate_hierarchy.ndexupload import NDExHierarchyUploader\n",
    "\n",
    "#Specify NDEx server\n",
    "ndexserver = 'public.ndexbio.org'\n",
    "ndexuser = ''\n",
    "ndexpassword = ''\n",
    "    \n",
    "# Specify paths to hierarchy and its parent (you can find example files in examples directory in cellmaps_generate_hierarchy_repo)\n",
    "hierarchy_path = './5.2_old_hierarchy_paclitaxel/hierarchy.cx2'\n",
    "parent_network_path = './5.2_old_hierarchy_paclitaxel/hierarchy_parent.cx2'\n",
    "\n",
    "# Load the hierarchy and parent network CX2 files into network objects\n",
    "factory = RawCX2NetworkFactory()\n",
    "hierarchy_network = factory.get_cx2network(hierarchy_path)\n",
    "parent_network = factory.get_cx2network(parent_network_path)\n",
    "\n",
    "# Initialize NDExHierarchyUploader with the specified NDEx server and credentials\n",
    "uploader = NDExHierarchyUploader(ndexserver, ndexuser, ndexpassword, visibility=True)\n",
    "\n",
    "# Upload the hierarchy and parent network to NDEx\n",
    "parent_uuid, parenturl, hierarchy_uuid, hierarchyurl = uploader.save_hierarchy_and_parent_network(hierarchy_network, parent_network)\n",
    "\n",
    "print(f\"Parent network UUID is {parent_uuid} and its URL in NDEx is {parenturl}\")\n",
    "print(f\"Hierarchy network UUID is {hierarchy_uuid} and its URL in NDEx is {hierarchyurl}\")\n",
    "\n",
    "# # Another option is to just specify the directory where the files are placed\n",
    "# _, _, _, hierarchyurl = uploader.upload_hierary_and_parent_network_from_files('./examples/')\n",
    "# print(f'Hierarchy uploaded. To view the hierarchy, paste this URL in your browser: {hierarchyurl}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b688cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving embedding: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.02632737159729004 seconds\n",
      "Jaccard graph constructed in 1.7703278064727783 seconds\n",
      "Wrote graph to binary file in 0.0015778541564941406 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.667759\n",
      "Louvain completed 21 runs in 0.11074137687683105 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 3.764559030532837 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.01603984832763672 seconds\n",
      "Jaccard graph constructed in 1.8280022144317627 seconds\n",
      "Wrote graph to binary file in 0.0021767616271972656 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.687609\n",
      "After 7 runs, maximum modularity is Q = 0.689447\n",
      "Louvain completed 27 runs in 0.10811209678649902 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 3.8001787662506104 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.01610541343688965 seconds\n",
      "Jaccard graph constructed in 1.7579221725463867 seconds\n",
      "Wrote graph to binary file in 0.002030611038208008 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.50925\n",
      "After 13 runs, maximum modularity is Q = 0.510263\n",
      "After 14 runs, maximum modularity is Q = 0.511542\n",
      "After 27 runs, maximum modularity is Q = 0.512822\n",
      "After 38 runs, maximum modularity is Q = 0.51391\n",
      "Louvain completed 58 runs in 0.2337043285369873 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 3.742588520050049 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.015324592590332031 seconds\n",
      "Jaccard graph constructed in 1.725459337234497 seconds\n",
      "Wrote graph to binary file in 0.0016415119171142578 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.648629\n",
      "After 2 runs, maximum modularity is Q = 0.653051\n",
      "Louvain completed 22 runs in 0.09271717071533203 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 3.661029815673828 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.014887332916259766 seconds\n",
      "Jaccard graph constructed in 1.7699623107910156 seconds\n",
      "Wrote graph to binary file in 0.0025949478149414062 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.659752\n",
      "After 2 runs, maximum modularity is Q = 0.665465\n",
      "After 3 runs, maximum modularity is Q = 0.667351\n",
      "Louvain completed 23 runs in 0.10291433334350586 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 3.640275239944458 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.015944480895996094 seconds\n",
      "Jaccard graph constructed in 1.7609891891479492 seconds\n",
      "Wrote graph to binary file in 0.001575469970703125 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.728844\n",
      "Louvain completed 21 runs in 0.07944202423095703 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 3.601919651031494 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.014929056167602539 seconds\n",
      "Jaccard graph constructed in 1.840831995010376 seconds\n",
      "Wrote graph to binary file in 0.002356290817260742 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.66025\n",
      "After 2 runs, maximum modularity is Q = 0.669071\n",
      "Louvain completed 22 runs in 0.09565234184265137 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 3.8038151264190674 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.20072674751281738 seconds\n",
      "Jaccard graph constructed in 1.803922176361084 seconds\n",
      "Wrote graph to binary file in 0.002893686294555664 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.731826\n",
      "After 2 runs, maximum modularity is Q = 0.733017\n",
      "Louvain completed 22 runs in 0.09175348281860352 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 3.9107165336608887 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving embedding: 97it [00:39,  2.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell map vorinostat\n",
    "\n",
    "from cellmaps_coembedding.runner import MuseCoEmbeddingGenerator\n",
    "from cellmaps_coembedding.runner import CellmapsCoEmbedder\n",
    "\n",
    "ppi_embeddingdir = '2.ppi_embedding'\n",
    "image_embeddingdir = 'embedding_old/vorinostat'\n",
    "outdir = '3_old.coembedding_vorinostat'\n",
    "gen = MuseCoEmbeddingGenerator(ppi_embeddingdir=ppi_embeddingdir,\n",
    "                               image_embeddingdir=image_embeddingdir,\n",
    "                               outdir=os.path.abspath(outdir))\n",
    "\n",
    "x = CellmapsCoEmbedder(outdir=outdir,\n",
    "                      inputdirs=[ppi_embeddingdir, image_embeddingdir],\n",
    "                      embedding_generator=gen)\n",
    "x.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4869a36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "input_file = \"embedding_old/vorinostat/image_emd.tsv\"\n",
    "# Store embeddings per gene\n",
    "data = defaultdict(list)\n",
    "# Read the original file\n",
    "with open(input_file, \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    header = next(reader) # store header\n",
    "    for row in reader:\n",
    "        gene_id = row[0]\n",
    "        embedding = list(map(float, row[1:]))\n",
    "        data[gene_id].append(embedding)\n",
    "# Compute mean and overwrite the same file\n",
    "with open(input_file, \"w\", newline='') as out:\n",
    "    writer = csv.writer(out, delimiter='\\t')\n",
    "    writer.writerow([\"id\"] + header[1:]) # write header back\n",
    "    for gene_id, vectors in data.items():\n",
    "        arr = np.array(vectors)\n",
    "        mean_vector = np.mean(arr, axis=0)\n",
    "        writer.writerow([gene_id] + mean_vector.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cfa386a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique genes: 461\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "input_file = \"embedding_old/vorinostat/image_emd.tsv\"\n",
    "unique_genes = set()\n",
    "with open(input_file, \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    next(reader) # skip header\n",
    "    for row in reader:\n",
    "        gene_id = row[0]\n",
    "        unique_genes.add(gene_id)\n",
    "print(f\"Number of unique genes: {len(unique_genes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "727d5703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating hierarchy: 15it [00:00, 80.57it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hnguye24/.conda/envs/yolo7/lib/python3.10/site-packages/cellmaps_generate_hierarchy/runner.py:623: UserWarning: Layout disabled due to incompatibilities with HCX format\n",
      "  warnings.warn(\"Layout disabled due to incompatibilities with HCX format\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cellmaps_generate_hierarchy.ppi import CosineSimilarityPPIGenerator\n",
    "from cellmaps_generate_hierarchy.hierarchy import CDAPSHiDeFHierarchyGenerator\n",
    "from cellmaps_generate_hierarchy.maturehierarchy import HiDeFHierarchyRefiner\n",
    "from cellmaps_generate_hierarchy.hcx import HCXFromCDAPSCXHierarchy\n",
    "from cellmaps_generate_hierarchy.runner import CellmapsGenerateHierarchy\n",
    "\n",
    "inputdir = '3_old.coembedding_vorinostat'\n",
    "outdir = '5.2_old_hierarchy_vorinostat'\n",
    "ppigen = CosineSimilarityPPIGenerator(embeddingdirs=[inputdir])\n",
    "\n",
    "refiner = HiDeFHierarchyRefiner()\n",
    "\n",
    "converter = HCXFromCDAPSCXHierarchy()\n",
    "\n",
    "hiergen = CDAPSHiDeFHierarchyGenerator(refiner=refiner,\n",
    "                                       hcxconverter=converter)\n",
    "\n",
    "x = CellmapsGenerateHierarchy(outdir=outdir,\n",
    "                              inputdirs=inputdir,\n",
    "                              ppigen=ppigen,\n",
    "                              hiergen=hiergen)\n",
    "x.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b413c328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent network UUID is 5cf8d8d3-9024-11f0-a218-005056ae3c32 and its URL in NDEx is https://www.ndexbio.org/viewer/networks/5cf8d8d3-9024-11f0-a218-005056ae3c32\n",
      "Hierarchy network UUID is 5d147725-9024-11f0-a218-005056ae3c32 and its URL in NDEx is https://www.ndexbio.org/viewer/networks/5d147725-9024-11f0-a218-005056ae3c32\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ndex2\n",
    "from ndex2.cx2 import RawCX2NetworkFactory\n",
    "from cellmaps_generate_hierarchy.ndexupload import NDExHierarchyUploader\n",
    "\n",
    "#Specify NDEx server\n",
    "ndexserver = 'public.ndexbio.org'\n",
    "ndexuser = ''\n",
    "ndexpassword = ''\n",
    "    \n",
    "# Specify paths to hierarchy and its parent (you can find example files in examples directory in cellmaps_generate_hierarchy_repo)\n",
    "hierarchy_path = './5.2_old_hierarchy_vorinostat/hierarchy.cx2'\n",
    "parent_network_path = './5.2_old_hierarchy_vorinostat/hierarchy_parent.cx2'\n",
    "\n",
    "# Load the hierarchy and parent network CX2 files into network objects\n",
    "factory = RawCX2NetworkFactory()\n",
    "hierarchy_network = factory.get_cx2network(hierarchy_path)\n",
    "parent_network = factory.get_cx2network(parent_network_path)\n",
    "\n",
    "# Initialize NDExHierarchyUploader with the specified NDEx server and credentials\n",
    "uploader = NDExHierarchyUploader(ndexserver, ndexuser, ndexpassword, visibility=True)\n",
    "\n",
    "# Upload the hierarchy and parent network to NDEx\n",
    "parent_uuid, parenturl, hierarchy_uuid, hierarchyurl = uploader.save_hierarchy_and_parent_network(hierarchy_network, parent_network)\n",
    "\n",
    "print(f\"Parent network UUID is {parent_uuid} and its URL in NDEx is {parenturl}\")\n",
    "print(f\"Hierarchy network UUID is {hierarchy_uuid} and its URL in NDEx is {hierarchyurl}\")\n",
    "\n",
    "# # Another option is to just specify the directory where the files are placed\n",
    "# _, _, _, hierarchyurl = uploader.upload_hierary_and_parent_network_from_files('./examples/')\n",
    "# print(f'Hierarchy uploaded. To view the hierarchy, paste this URL in your browser: {hierarchyurl}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ebba7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:.conda-yolo7]",
   "language": "python",
   "name": "conda-env-.conda-yolo7-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
