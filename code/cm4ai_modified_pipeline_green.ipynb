{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662989a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2025\n",
    "# Huu Phong Nguyen at Prof. Jake Chen's Lab\n",
    "# Department of Biomedical Informatics and Data Science\n",
    "# University of Alabama at Birmingham, USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd2ebeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir embedding_new_green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d28f87d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp outputs_green/file1_paclitaxel.tsv embedding_new_green/file1_paclitaxel.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9a2d379",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir embedding_new_green/paclitaxel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe0f48bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean values saved to: embedding_new_green/paclitaxel/image_emd.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load TSV file\n",
    "input_file = \"embedding_new_green/image_emd_new.tsv\"   # replace with your filename\n",
    "df = pd.read_csv(input_file, sep=\"\\t\")\n",
    "\n",
    "# Step 2: Compute mean per gene (assumes first column is \"id\" or \"Gene\")\n",
    "mean_df = df.groupby(df.columns[0]).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Step 3: Save to a new file\n",
    "output_file = \"embedding_new_green/paclitaxel/image_emd.tsv\"\n",
    "mean_df.to_csv(output_file, sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"Mean values saved to:\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f885cdb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34m1.ppi_download\u001b[0m/                      9606.protein.links.detailed.v12.0.txt.gz\r\n",
      "1.ppi_download.zip                   \u001b[01;34mcellmaps_ppidownloader_outdir\u001b[0m/\r\n",
      "\u001b[01;34m2.ppi_embedding\u001b[0m/                     cm4ai_network_4channels.ipynb\r\n",
      "\u001b[01;34m2.ppi_embedding_old\u001b[0m/                 cm4ai_network_green.ipynb\r\n",
      "\u001b[01;34m3_new.coembedding_paclitaxel_old\u001b[0m/    compare_file1_file2.txt\r\n",
      "\u001b[01;34m3_new.coembedding_untreated_old\u001b[0m/     \u001b[01;34mdata\u001b[0m/\r\n",
      "\u001b[01;34m3_new_green.coembedding_paclitaxel\u001b[0m/  \u001b[01;34mdata_green\u001b[0m/\r\n",
      "\u001b[01;34m3_old.coembedding_paclitaxel\u001b[0m/        demo1.ipynb\r\n",
      "\u001b[01;34m3_old.coembedding_untreated\u001b[0m/         \u001b[01;34membedding_bkp\u001b[0m/\r\n",
      "\u001b[01;34m3_old.coembedding_vorinostat\u001b[0m/        \u001b[01;34membedding_new_green\u001b[0m/\r\n",
      "\u001b[01;34m3_old_green.coembedding_paclitaxel\u001b[0m/  \u001b[01;34membedding_old\u001b[0m/\r\n",
      "\u001b[01;34m3_old_green.coembedding_untreated\u001b[0m/   \u001b[01;34membedding_old2\u001b[0m/\r\n",
      "\u001b[01;34m3_old_green.coembedding_vorinostat\u001b[0m/  \u001b[01;34membedding_old_green\u001b[0m/\r\n",
      "\u001b[01;34m5.2_new_hierarchy_old\u001b[0m/               \u001b[01;34mexamples\u001b[0m/\r\n",
      "\u001b[01;34m5.2_new_hierarchy_paclitaxel_old\u001b[0m/    \u001b[01;34mllema_outputs\u001b[0m/\r\n",
      "\u001b[01;34m5.2_old_green_hierarchy_paclitaxel\u001b[0m/  Modified_Pipline.ipynb\r\n",
      "\u001b[01;34m5.2_old_green_hierarchy_untreated\u001b[0m/   \u001b[01;34moutputs_green\u001b[0m/\r\n",
      "\u001b[01;34m5.2_old_green_hierarchy_vorinostat\u001b[0m/  seg1.ipynb\r\n",
      "\u001b[01;34m5.2_old_hierarchy_paclitaxel\u001b[0m/        Untitled1.ipynb\r\n",
      "\u001b[01;34m5.2_old_hierarchy_untreated\u001b[0m/         Untitled2.ipynb\r\n",
      "\u001b[01;34m5.2_old_hierarchy_vorinostat\u001b[0m/        Untitled3.ipynb\r\n",
      "\u001b[01;34m6.2_new_hierarchyeval_old\u001b[0m/           Untitled.ipynb\r\n",
      "9606.protein.info.v12.0.txt.gz\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576bd69f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774de3e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d580e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb1de31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d01fb9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Comparison finished → results saved in compare_file1_file2.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load both files (TSV format)\n",
    "file1 = pd.read_csv(\"outputs_green/image_emd new2.tsv\", sep=\"\\t\", dtype=str)\n",
    "file2 = pd.read_csv(\"outputs_green/image_emd_old.tsv\", sep=\"\\t\", dtype=str)\n",
    "\n",
    "# Extract the first column (assuming it's named 'id' or just the first column)\n",
    "col1_file1 = file1.iloc[:, 0]\n",
    "col1_file2 = file2.iloc[:, 0]\n",
    "\n",
    "# Find common and different IDs\n",
    "common_ids = set(col1_file1).intersection(set(col1_file2))\n",
    "only_in_file1 = set(col1_file1) - set(col1_file2)\n",
    "only_in_file2 = set(col1_file2) - set(col1_file1)\n",
    "\n",
    "# Save results\n",
    "with open(\"compare_file1_file2.txt\", \"w\") as f:\n",
    "    f.write(\"✅ Common IDs: {}\\n\\n\".format(len(common_ids)))\n",
    "    f.write(\"\\n\".join(sorted(common_ids)))\n",
    "    f.write(\"\\n\\n❌ Only in file1 ({}):\\n\".format(len(only_in_file1)))\n",
    "    f.write(\"\\n\".join(sorted(only_in_file1)))\n",
    "    f.write(\"\\n\\n❌ Only in file2 ({}):\\n\".format(len(only_in_file2)))\n",
    "    f.write(\"\\n\".join(sorted(only_in_file2)))\n",
    "\n",
    "print(\"✅ Comparison finished → results saved in compare_file1_file2.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b016a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell map vorinostat\n",
    "\n",
    "from cellmaps_coembedding.runner import MuseCoEmbeddingGenerator\n",
    "from cellmaps_coembedding.runner import CellmapsCoEmbedder\n",
    "\n",
    "ppi_embeddingdir = '2.ppi_embedding'\n",
    "image_embeddingdir = 'embedding_new_green/paclitaxel'\n",
    "outdir = '3_new_green.coembedding_paclitaxel'\n",
    "gen = MuseCoEmbeddingGenerator(ppi_embeddingdir=ppi_embeddingdir,\n",
    "                               image_embeddingdir=image_embeddingdir,\n",
    "                               outdir=os.path.abspath(outdir))\n",
    "\n",
    "x = CellmapsCoEmbedder(outdir=outdir,\n",
    "                      inputdirs=[ppi_embeddingdir, image_embeddingdir],\n",
    "                      embedding_generator=gen)\n",
    "x.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1eb882ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean values saved to: outputs_green/tmp/paclitaxel_image_emd _step3_means.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load TSV file\n",
    "input_file = \"outputs_green/tmp/paclitaxel_image_emd _step3.tsv\"   # replace with your filename\n",
    "df = pd.read_csv(input_file, sep=\"\\t\")\n",
    "\n",
    "# Step 2: Compute mean per gene (assumes first column is \"id\" or \"Gene\")\n",
    "mean_df = df.groupby(df.columns[0]).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Step 3: Save to a new file\n",
    "output_file = \"outputs_green/tmp/paclitaxel_image_emd _step3_means.tsv\"\n",
    "mean_df.to_csv(output_file, sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"Mean values saved to:\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d017f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Comparison finished → results saved in compare_file1_file2.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load both files (TSV format)\n",
    "file1 = pd.read_csv(\"outputs_green/tmp/paclitaxel_image_emd _step3_means.tsv\", sep=\"\\t\", dtype=str)\n",
    "file2 = pd.read_csv(\"outputs_green/tmp/image_emd_old.tsv\", sep=\"\\t\", dtype=str)\n",
    "\n",
    "# Extract the first column (assuming it's named 'id' or just the first column)\n",
    "col1_file1 = file1.iloc[:, 0]\n",
    "col1_file2 = file2.iloc[:, 0]\n",
    "\n",
    "# Find common and different IDs\n",
    "common_ids = set(col1_file1).intersection(set(col1_file2))\n",
    "only_in_file1 = set(col1_file1) - set(col1_file2)\n",
    "only_in_file2 = set(col1_file2) - set(col1_file1)\n",
    "\n",
    "# Save results\n",
    "with open(\"outputs_green/tmp/compare_file1_file2_step3.txt\", \"w\") as f:\n",
    "    f.write(\"✅ Common IDs: {}\\n\\n\".format(len(common_ids)))\n",
    "    f.write(\"\\n\".join(sorted(common_ids)))\n",
    "    f.write(\"\\n\\n❌ Only in file1 ({}):\\n\".format(len(only_in_file1)))\n",
    "    f.write(\"\\n\".join(sorted(only_in_file1)))\n",
    "    f.write(\"\\n\\n❌ Only in file2 ({}):\\n\".format(len(only_in_file2)))\n",
    "    f.write(\"\\n\".join(sorted(only_in_file2)))\n",
    "\n",
    "print(\"✅ Comparison finished → results saved in compare_file1_file2.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "150d5296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean values saved to: outputs_green/tmp/paclitaxel_image_emd _step3_means.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load TSV file\n",
    "input_file = \"outputs_green/tmp/paclitaxel_image_emd _step3_means.tsv\"   # replace with your filename\n",
    "df = pd.read_csv(input_file, sep=\"\\t\")\n",
    "\n",
    "# Step 2: Compute mean per gene (assumes first column is \"id\" or \"Gene\")\n",
    "mean_df = df.groupby(df.columns[0]).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Step 3: Save to a new file\n",
    "output_file = \"outputs_green/tmp/paclitaxel_image_emd _step3_means.tsv\"\n",
    "mean_df.to_csv(output_file, sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"Mean values saved to:\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8cb6f97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Comparison finished → results saved in compare_file1_file2_v2.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load both files (TSV format)\n",
    "file1 = pd.read_csv(\"outputs_green/tmp/paclitaxel_image_emd _step3_means.tsv\", sep=\"\\t\", dtype=str)\n",
    "file2 = pd.read_csv(\"outputs_green/tmp/image_emd_old.tsv\", sep=\"\\t\", dtype=str)\n",
    "\n",
    "# Extract the first column (assuming it's named 'id' or just the first column)\n",
    "col1_file1 = file1.iloc[:, 0]\n",
    "col1_file2 = file2.iloc[:, 0]\n",
    "\n",
    "# Find common and different IDs\n",
    "common_ids = set(col1_file1).intersection(set(col1_file2))\n",
    "only_in_file1 = set(col1_file1) - set(col1_file2)\n",
    "only_in_file2 = set(col1_file2) - set(col1_file1)\n",
    "\n",
    "# Save results\n",
    "with open(\"outputs_green/tmp/compare_file1_file2_step3_v2.txt\", \"w\") as f:\n",
    "    f.write(\"✅ Common IDs: {}\\n\\n\".format(len(common_ids)))\n",
    "    f.write(\"\\n\".join(sorted(common_ids)))\n",
    "    f.write(\"\\n\\n❌ Only in file1 ({}):\\n\".format(len(only_in_file1)))\n",
    "    f.write(\"\\n\".join(sorted(only_in_file1)))\n",
    "    f.write(\"\\n\\n❌ Only in file2 ({}):\\n\".format(len(only_in_file2)))\n",
    "    f.write(\"\\n\".join(sorted(only_in_file2)))\n",
    "\n",
    "print(\"✅ Comparison finished → results saved in compare_file1_file2_v2.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c039dcb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Comparison finished → results saved in compare_file1_file2_v3.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load both files (TSV format)\n",
    "file1 = pd.read_csv(\"outputs_green/tmp/paclitaxel_image_emd _step3_means.tsv\", sep=\"\\t\", dtype=str)\n",
    "file2 = pd.read_csv(\"outputs_green/tmp/image_emd_old.tsv\", sep=\"\\t\", dtype=str)\n",
    "\n",
    "# Extract the first column (assuming it's named 'id' or just the first column)\n",
    "col1_file1 = file1.iloc[:, 0]\n",
    "col1_file2 = file2.iloc[:, 0]\n",
    "\n",
    "# Find common and different IDs\n",
    "common_ids = set(col1_file1).intersection(set(col1_file2))\n",
    "only_in_file1 = set(col1_file1) - set(col1_file2)\n",
    "only_in_file2 = set(col1_file2) - set(col1_file1)\n",
    "\n",
    "# Save results\n",
    "with open(\"outputs_green/tmp/compare_file1_file2_step3_v3.txt\", \"w\") as f:\n",
    "    f.write(\"✅ Common IDs: {}\\n\\n\".format(len(common_ids)))\n",
    "    f.write(\"\\n\".join(sorted(common_ids)))\n",
    "    f.write(\"\\n\\n❌ Only in file1 ({}):\\n\".format(len(only_in_file1)))\n",
    "    f.write(\"\\n\".join(sorted(only_in_file1)))\n",
    "    f.write(\"\\n\\n❌ Only in file2 ({}):\\n\".format(len(only_in_file2)))\n",
    "    f.write(\"\\n\".join(sorted(only_in_file2)))\n",
    "\n",
    "print(\"✅ Comparison finished → results saved in compare_file1_file2_v3.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "83be738c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Comparison finished → results saved in compare_file1_file2_v4.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load both files (TSV format)\n",
    "file1 = pd.read_csv(\"outputs_green/tmp/paclitaxel_image_emd _step3_means.tsv\", sep=\"\\t\", dtype=str)\n",
    "file2 = pd.read_csv(\"outputs_green/tmp/image_emd_old.tsv\", sep=\"\\t\", dtype=str)\n",
    "\n",
    "# Extract the first column (assuming it's named 'id' or just the first column)\n",
    "col1_file1 = file1.iloc[:, 0]\n",
    "col1_file2 = file2.iloc[:, 0]\n",
    "\n",
    "# Find common and different IDs\n",
    "common_ids = set(col1_file1).intersection(set(col1_file2))\n",
    "only_in_file1 = set(col1_file1) - set(col1_file2)\n",
    "only_in_file2 = set(col1_file2) - set(col1_file1)\n",
    "\n",
    "# Save results\n",
    "with open(\"outputs_green/tmp/compare_file1_file2_step3_v4.txt\", \"w\") as f:\n",
    "    f.write(\"✅ Common IDs: {}\\n\\n\".format(len(common_ids)))\n",
    "    f.write(\"\\n\".join(sorted(common_ids)))\n",
    "    f.write(\"\\n\\n❌ Only in file1 ({}):\\n\".format(len(only_in_file1)))\n",
    "    f.write(\"\\n\".join(sorted(only_in_file1)))\n",
    "    f.write(\"\\n\\n❌ Only in file2 ({}):\\n\".format(len(only_in_file2)))\n",
    "    f.write(\"\\n\".join(sorted(only_in_file2)))\n",
    "\n",
    "print(\"✅ Comparison finished → results saved in compare_file1_file2_v4.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bad4410e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: target ‘embedding_new_green/paclitaxel/image_emd.tsv’ is not a directory\r\n"
     ]
    }
   ],
   "source": [
    "#copy file\n",
    "!cp outputs_green/tmp/paclitaxel_image_emd _step3_means.tsv embedding_new_green/paclitaxel/image_emd.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ec1e3c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean values saved to: embedding_new_green/paclitaxel/image_emd.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load TSV file\n",
    "input_file = \"embedding_new_green/paclitaxel/image_emd.tsv\"   # replace with your filename\n",
    "df = pd.read_csv(input_file, sep=\"\\t\")\n",
    "\n",
    "# Step 2: Compute mean per gene (assumes first column is \"id\" or \"Gene\")\n",
    "mean_df = df.groupby(df.columns[0]).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Step 3: Save to a new file\n",
    "output_file = \"embedding_new_green/paclitaxel/image_emd.tsv\"\n",
    "mean_df.to_csv(output_file, sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"Mean values saved to:\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "98bbb9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving embedding: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.03830742835998535 seconds\n",
      "Jaccard graph constructed in 1.2873845100402832 seconds\n",
      "Wrote graph to binary file in 0.0038177967071533203 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.667759\n",
      "Louvain completed 21 runs in 0.07613396644592285 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.665189504623413 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.018754243850708008 seconds\n",
      "Jaccard graph constructed in 1.2869431972503662 seconds\n",
      "Wrote graph to binary file in 0.0020914077758789062 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.627338\n",
      "After 2 runs, maximum modularity is Q = 0.628672\n",
      "After 4 runs, maximum modularity is Q = 0.631424\n",
      "Louvain completed 24 runs in 0.10246825218200684 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.6697170734405518 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.01907038688659668 seconds\n",
      "Jaccard graph constructed in 1.2798175811767578 seconds\n",
      "Wrote graph to binary file in 0.002496480941772461 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.526066\n",
      "After 5 runs, maximum modularity is Q = 0.528991\n",
      "Louvain completed 25 runs in 0.09744954109191895 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.656519651412964 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.01683974266052246 seconds\n",
      "Jaccard graph constructed in 1.2692620754241943 seconds\n",
      "Wrote graph to binary file in 0.0027704238891601562 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.575471\n",
      "After 2 runs, maximum modularity is Q = 0.577234\n",
      "After 4 runs, maximum modularity is Q = 0.578443\n",
      "Louvain completed 24 runs in 0.10466694831848145 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.6793549060821533 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.01825094223022461 seconds\n",
      "Jaccard graph constructed in 1.2784221172332764 seconds\n",
      "Wrote graph to binary file in 0.006745338439941406 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.685227\n",
      "Louvain completed 21 runs in 0.07596445083618164 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.6426355838775635 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.019086599349975586 seconds\n",
      "Jaccard graph constructed in 1.26179838180542 seconds\n",
      "Wrote graph to binary file in 0.0025758743286132812 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.73185\n",
      "Louvain completed 21 runs in 0.07444930076599121 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.64397931098938 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.08539438247680664 seconds\n",
      "Jaccard graph constructed in 1.2380409240722656 seconds\n",
      "Wrote graph to binary file in 0.004453897476196289 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.679084\n",
      "Louvain completed 21 runs in 0.07601785659790039 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.6389007568359375 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 1.8986899852752686 seconds\n",
      "Jaccard graph constructed in 1.0926718711853027 seconds\n",
      "Wrote graph to binary file in 0.0018939971923828125 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.742649\n",
      "Louvain completed 21 runs in 0.07497000694274902 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 4.1520750522613525 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving embedding: 97it [00:32,  3.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell map vorinostat\n",
    "\n",
    "from cellmaps_coembedding.runner import MuseCoEmbeddingGenerator\n",
    "from cellmaps_coembedding.runner import CellmapsCoEmbedder\n",
    "\n",
    "ppi_embeddingdir = '2.ppi_embedding'\n",
    "image_embeddingdir = 'embedding_new_green/paclitaxel'\n",
    "outdir = '3_new_green.coembedding_paclitaxel'\n",
    "gen = MuseCoEmbeddingGenerator(ppi_embeddingdir=ppi_embeddingdir,\n",
    "                               image_embeddingdir=image_embeddingdir,\n",
    "                               outdir=os.path.abspath(outdir))\n",
    "\n",
    "x = CellmapsCoEmbedder(outdir=outdir,\n",
    "                      inputdirs=[ppi_embeddingdir, image_embeddingdir],\n",
    "                      embedding_generator=gen)\n",
    "x.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "caf3381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "input_file = \"embedding_new_green/paclitaxel/image_emd.tsv\"\n",
    "# Store embeddings per gene\n",
    "data = defaultdict(list)\n",
    "# Read the original file\n",
    "with open(input_file, \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    header = next(reader) # store header\n",
    "    for row in reader:\n",
    "        gene_id = row[0]\n",
    "        embedding = list(map(float, row[1:]))\n",
    "        data[gene_id].append(embedding)\n",
    "# Compute mean and overwrite the same file\n",
    "with open(input_file, \"w\", newline='') as out:\n",
    "    writer = csv.writer(out, delimiter='\\t')\n",
    "    writer.writerow([\"id\"] + header[1:]) # write header back\n",
    "    for gene_id, vectors in data.items():\n",
    "        arr = np.array(vectors)\n",
    "        mean_vector = np.mean(arr, axis=0)\n",
    "        writer.writerow([gene_id] + mean_vector.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9780c873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique genes: 461\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "input_file = \"embedding_new_green/paclitaxel/image_emd.tsv\"\n",
    "unique_genes = set()\n",
    "with open(input_file, \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    next(reader) # skip header\n",
    "    for row in reader:\n",
    "        gene_id = row[0]\n",
    "        unique_genes.add(gene_id)\n",
    "print(f\"Number of unique genes: {len(unique_genes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3c9aeff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating hierarchy: 15it [00:00, 72.36it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/hnguye24/.conda/envs/yolo7/lib/python3.10/site-packages/cellmaps_generate_hierarchy/runner.py:623: UserWarning: Layout disabled due to incompatibilities with HCX format\n",
      "  warnings.warn(\"Layout disabled due to incompatibilities with HCX format\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cellmaps_generate_hierarchy.ppi import CosineSimilarityPPIGenerator\n",
    "from cellmaps_generate_hierarchy.hierarchy import CDAPSHiDeFHierarchyGenerator\n",
    "from cellmaps_generate_hierarchy.maturehierarchy import HiDeFHierarchyRefiner\n",
    "from cellmaps_generate_hierarchy.hcx import HCXFromCDAPSCXHierarchy\n",
    "from cellmaps_generate_hierarchy.runner import CellmapsGenerateHierarchy\n",
    "\n",
    "inputdir = '3_new_green.coembedding_paclitaxel'\n",
    "outdir = '5.2_new_green_hierarchy_paclitaxel'\n",
    "ppigen = CosineSimilarityPPIGenerator(embeddingdirs=[inputdir])\n",
    "\n",
    "refiner = HiDeFHierarchyRefiner()\n",
    "\n",
    "converter = HCXFromCDAPSCXHierarchy()\n",
    "\n",
    "hiergen = CDAPSHiDeFHierarchyGenerator(refiner=refiner,\n",
    "                                       hcxconverter=converter)\n",
    "\n",
    "x = CellmapsGenerateHierarchy(outdir=outdir,\n",
    "                              inputdirs=inputdir,\n",
    "                              ppigen=ppigen,\n",
    "                              hiergen=hiergen)\n",
    "x.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5206adb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ndex2\n",
    "from ndex2.cx2 import RawCX2NetworkFactory\n",
    "from cellmaps_generate_hierarchy.ndexupload import NDExHierarchyUploader\n",
    "\n",
    "#Specify NDEx server\n",
    "ndexserver = 'public.ndexbio.org'\n",
    "ndexuser = ''\n",
    "ndexpassword = ''\n",
    "    \n",
    "# Specify paths to hierarchy and its parent (you can find example files in examples directory in cellmaps_generate_hierarchy_repo)\n",
    "hierarchy_path = './5.2_new_green_hierarchy_paclitaxel/hierarchy.cx2'\n",
    "parent_network_path = './5.2_new_green_hierarchy_paclitaxel/hierarchy_parent.cx2'\n",
    "\n",
    "# Load the hierarchy and parent network CX2 files into network objects\n",
    "factory = RawCX2NetworkFactory()\n",
    "hierarchy_network = factory.get_cx2network(hierarchy_path)\n",
    "parent_network = factory.get_cx2network(parent_network_path)\n",
    "\n",
    "# Initialize NDExHierarchyUploader with the specified NDEx server and credentials\n",
    "uploader = NDExHierarchyUploader(ndexserver, ndexuser, ndexpassword, visibility=True)\n",
    "\n",
    "# Upload the hierarchy and parent network to NDEx\n",
    "parent_uuid, parenturl, hierarchy_uuid, hierarchyurl = uploader.save_hierarchy_and_parent_network(hierarchy_network, parent_network)\n",
    "\n",
    "print(f\"Parent network UUID is {parent_uuid} and its URL in NDEx is {parenturl}\")\n",
    "print(f\"Hierarchy network UUID is {hierarchy_uuid} and its URL in NDEx is {hierarchyurl}\")\n",
    "\n",
    "# # Another option is to just specify the directory where the files are placed\n",
    "# _, _, _, hierarchyurl = uploader.upload_hierary_and_parent_network_from_files('./examples/')\n",
    "# print(f'Hierarchy uploaded. To view the hierarchy, paste this URL in your browser: {hierarchyurl}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "93cafd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir embedding_new_green/untreated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4cee13bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean values saved to: outputs_green/tmp/untreated_image_emd_means.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load TSV file\n",
    "input_file = \"outputs_green/untreated_image_emd.tsv\"   # replace with your filename\n",
    "df = pd.read_csv(input_file, sep=\"\\t\")\n",
    "\n",
    "# Step 2: Compute mean per gene (assumes first column is \"id\" or \"Gene\")\n",
    "mean_df = df.groupby(df.columns[0]).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Step 3: Save to a new file\n",
    "output_file = \"outputs_green/tmp/untreated_image_emd_means.tsv\"\n",
    "mean_df.to_csv(output_file, sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"Mean values saved to:\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2fb98616",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp embedding_old_green/untreated/image_emd.tsv outputs_green/tmp/untreated_image_emd_old.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392217bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f11d46e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fe129a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 3976\n",
      "Column names: ['Gene_Name_HPA,Baselink']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"outputs_green/tmp/manifest_untreated_step1.csv\", sep=\"\\t\")\n",
    "\n",
    "# Total rows (excluding header)\n",
    "print(\"Number of rows:\", len(df))\n",
    "\n",
    "# Show column names exactly as read\n",
    "print(\"Column names:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ccdb802f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Saved compact names like 'B2AI_3_untreated_C2_R1_z01' → output_compact.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# # Open the file and print each line\n",
    "# with open(\"outputs_green/tmp/manifest_untreated_step2.csv\", \"r\") as f:\n",
    "#     for i, line in enumerate(f, start=1):\n",
    "#         print(f\"{i}: {line.strip()}\")\n",
    "\n",
    "\n",
    "# Open input file and write to output file\n",
    "with open(\"outputs_green/tmp/manifest_untreated_step2.csv\", \"r\") as f_in, \\\n",
    "     open(\"outputs_green/tmp/manifest_untreated_step3.csv\", \"w\") as f_out:\n",
    "    \n",
    "    for i, line in enumerate(f_in, start=1):\n",
    "        if i == 1:  # skip header line\n",
    "            continue\n",
    "        line = line.strip()\n",
    "        # Match compact name pattern: B2AI_*_z##\n",
    "        match = re.search(r\"(B2AI_[^/]*?_z\\d{2})\", line)\n",
    "        if match:\n",
    "            compact = match.group(1)\n",
    "            f_out.write(compact + \"\\n\")\n",
    "\n",
    "print(\"Done! Saved compact names like 'B2AI_3_untreated_C2_R1_z01' → output_compact.tsv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "248f86cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Step 1: Load dictionary into memory\n",
    "id_to_gene = {}\n",
    "with open(\"outputs_green/tmp/manifest_untreated_step1_m.csv\", \"r\") as f:\n",
    "    next(f)  # skip header\n",
    "    for line in f:\n",
    "        gene, compact_id = line.strip().split(\",\")\n",
    "        id_to_gene[compact_id] = gene\n",
    "\n",
    "# Step 2: Process TSV line by line\n",
    "with open(\"outputs_green/tmp/untreated_image_emd_means_step1.tsv\", \"r\") as f_in, \\\n",
    "     open(\"outputs_green/tmp/untreated_image_emd_means_step1_with_gene_v2.tsv\", \"w\") as f_out:\n",
    "\n",
    "    header = f_in.readline().strip()\n",
    "    f_out.write(header + \"\\tGene_Name_HPA\\n\")  # add new column\n",
    "\n",
    "    for line in f_in:\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        if not parts or len(parts) < 1:\n",
    "            continue\n",
    "\n",
    "        img_id = parts[0]\n",
    "\n",
    "        # Extract compact ID\n",
    "        compact_id = re.sub(r\"^untreated__|_green\\.png$\", \"\", img_id)\n",
    "\n",
    "        # Look up gene name\n",
    "        gene_name = id_to_gene.get(compact_id, \"NA\")\n",
    "\n",
    "        # Write output\n",
    "        f_out.write(line.strip() + \"\\t\" + gene_name + \"\\n\")\n",
    "        print(img_id, compact_id, gene_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b6a6e4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean values saved to: outputs_green/tmp/untreated_image_emd_updatedgene_means.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load TSV file\n",
    "input_file = \"outputs_green/tmp/untreated_image_emd_updatedgene.tsv\"   # replace with your filename\n",
    "df = pd.read_csv(input_file, sep=\"\\t\")\n",
    "\n",
    "# Step 2: Compute mean per gene (assumes first column is \"id\" or \"Gene\")\n",
    "mean_df = df.groupby(df.columns[0]).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Step 3: Save to a new file\n",
    "output_file = \"outputs_green/tmp/untreated_image_emd_updatedgene_means.tsv\"\n",
    "mean_df.to_csv(output_file, sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"Mean values saved to:\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0c9ab804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Comparison finished → resultst\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load both files (TSV format)\n",
    "file1 = pd.read_csv(\"outputs_green/tmp/untreated_image_emd_updatedgene_means.tsv\", sep=\"\\t\", dtype=str)\n",
    "file2 = pd.read_csv(\"outputs_green/tmp/untreated_image_emd_old.tsv\", sep=\"\\t\", dtype=str)\n",
    "\n",
    "# Extract the first column (assuming it's named 'id' or just the first column)\n",
    "col1_file1 = file1.iloc[:, 0]\n",
    "col1_file2 = file2.iloc[:, 0]\n",
    "\n",
    "# Find common and different IDs\n",
    "common_ids = set(col1_file1).intersection(set(col1_file2))\n",
    "only_in_file1 = set(col1_file1) - set(col1_file2)\n",
    "only_in_file2 = set(col1_file2) - set(col1_file1)\n",
    "\n",
    "# Save results\n",
    "with open(\"outputs_green/tmp/compare_untreated_v2.txt\", \"w\") as f:\n",
    "    f.write(\"✅ Common IDs: {}\\n\\n\".format(len(common_ids)))\n",
    "    f.write(\"\\n\".join(sorted(common_ids)))\n",
    "    f.write(\"\\n\\n❌ Only in file1 ({}):\\n\".format(len(only_in_file1)))\n",
    "    f.write(\"\\n\".join(sorted(only_in_file1)))\n",
    "    f.write(\"\\n\\n❌ Only in file2 ({}):\\n\".format(len(only_in_file2)))\n",
    "    f.write(\"\\n\".join(sorted(only_in_file2)))\n",
    "\n",
    "print(\"✅ Comparison finished → resultst\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c5221463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Comparison finished → resultst\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load both files (TSV format)\n",
    "file1 = pd.read_csv(\"outputs_green/tmp/untreated_image_emd_updatedgene_means.tsv\", sep=\"\\t\", dtype=str)\n",
    "file2 = pd.read_csv(\"outputs_green/tmp/untreated_image_emd_old.tsv\", sep=\"\\t\", dtype=str)\n",
    "\n",
    "# Extract the first column (assuming it's named 'id' or just the first column)\n",
    "col1_file1 = file1.iloc[:, 0]\n",
    "col1_file2 = file2.iloc[:, 0]\n",
    "\n",
    "# Find common and different IDs\n",
    "common_ids = set(col1_file1).intersection(set(col1_file2))\n",
    "only_in_file1 = set(col1_file1) - set(col1_file2)\n",
    "only_in_file2 = set(col1_file2) - set(col1_file1)\n",
    "\n",
    "# Save results\n",
    "with open(\"outputs_green/tmp/compare_untreated_v3.txt\", \"w\") as f:\n",
    "    f.write(\"✅ Common IDs: {}\\n\\n\".format(len(common_ids)))\n",
    "    f.write(\"\\n\".join(sorted(common_ids)))\n",
    "    f.write(\"\\n\\n❌ Only in file1 ({}):\\n\".format(len(only_in_file1)))\n",
    "    f.write(\"\\n\".join(sorted(only_in_file1)))\n",
    "    f.write(\"\\n\\n❌ Only in file2 ({}):\\n\".format(len(only_in_file2)))\n",
    "    f.write(\"\\n\".join(sorted(only_in_file2)))\n",
    "\n",
    "print(\"✅ Comparison finished → resultst\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d6fdd312",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp outputs_green/tmp/untreated_image_emd_updatedgene_means.tsv embedding_new_green/untreated/image_emd.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1c6aa176",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving embedding: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.07844805717468262 seconds\n",
      "Jaccard graph constructed in 1.105147361755371 seconds\n",
      "Wrote graph to binary file in 0.002071380615234375 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.666756\n",
      "After 3 runs, maximum modularity is Q = 0.667759\n",
      "Louvain completed 23 runs in 0.09318757057189941 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.3473267555236816 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.02701401710510254 seconds\n",
      "Jaccard graph constructed in 1.104712724685669 seconds\n",
      "Wrote graph to binary file in 0.006388664245605469 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.643497\n",
      "Louvain completed 21 runs in 0.07945966720581055 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.288811445236206 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.03547239303588867 seconds\n",
      "Jaccard graph constructed in 1.0907576084136963 seconds\n",
      "Wrote graph to binary file in 0.0019431114196777344 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.508563\n",
      "After 3 runs, maximum modularity is Q = 0.50977\n",
      "Louvain completed 23 runs in 0.09656167030334473 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.305972099304199 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.018674373626708984 seconds\n",
      "Jaccard graph constructed in 1.1107852458953857 seconds\n",
      "Wrote graph to binary file in 0.0024662017822265625 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.590453\n",
      "After 2 runs, maximum modularity is Q = 0.598028\n",
      "Louvain completed 22 runs in 0.09201574325561523 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.2646403312683105 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.016649723052978516 seconds\n",
      "Jaccard graph constructed in 1.0584807395935059 seconds\n",
      "Wrote graph to binary file in 0.001661539077758789 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.674536\n",
      "After 2 runs, maximum modularity is Q = 0.678461\n",
      "Louvain completed 22 runs in 0.09381318092346191 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.251847505569458 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.02925276756286621 seconds\n",
      "Jaccard graph constructed in 1.056344985961914 seconds\n",
      "Wrote graph to binary file in 0.0032083988189697266 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.742868\n",
      "Louvain completed 21 runs in 0.07812619209289551 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.2092814445495605 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.0288240909576416 seconds\n",
      "Jaccard graph constructed in 1.0499866008758545 seconds\n",
      "Wrote graph to binary file in 0.0014801025390625 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.675262\n",
      "Louvain completed 21 runs in 0.07766580581665039 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.225144147872925 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.018014192581176758 seconds\n",
      "Jaccard graph constructed in 1.082857370376587 seconds\n",
      "Wrote graph to binary file in 0.002480030059814453 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.758887\n",
      "Louvain completed 21 runs in 0.07863759994506836 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.245598554611206 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving embedding: 97it [00:27,  3.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell map vorinostat\n",
    "\n",
    "from cellmaps_coembedding.runner import MuseCoEmbeddingGenerator\n",
    "from cellmaps_coembedding.runner import CellmapsCoEmbedder\n",
    "\n",
    "ppi_embeddingdir = '2.ppi_embedding'\n",
    "image_embeddingdir = 'embedding_new_green/untreated'\n",
    "outdir = '3_new_green.coembedding_untreated'\n",
    "gen = MuseCoEmbeddingGenerator(ppi_embeddingdir=ppi_embeddingdir,\n",
    "                               image_embeddingdir=image_embeddingdir,\n",
    "                               outdir=os.path.abspath(outdir))\n",
    "\n",
    "x = CellmapsCoEmbedder(outdir=outdir,\n",
    "                      inputdirs=[ppi_embeddingdir, image_embeddingdir],\n",
    "                      embedding_generator=gen)\n",
    "x.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4cf96df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "input_file = \"embedding_new_green/untreated/image_emd.tsv\"\n",
    "# Store embeddings per gene\n",
    "data = defaultdict(list)\n",
    "# Read the original file\n",
    "with open(input_file, \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    header = next(reader) # store header\n",
    "    for row in reader:\n",
    "        gene_id = row[0]\n",
    "        embedding = list(map(float, row[1:]))\n",
    "        data[gene_id].append(embedding)\n",
    "# Compute mean and overwrite the same file\n",
    "with open(input_file, \"w\", newline='') as out:\n",
    "    writer = csv.writer(out, delimiter='\\t')\n",
    "    writer.writerow([\"id\"] + header[1:]) # write header back\n",
    "    for gene_id, vectors in data.items():\n",
    "        arr = np.array(vectors)\n",
    "        mean_vector = np.mean(arr, axis=0)\n",
    "        writer.writerow([gene_id] + mean_vector.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "77d860e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique genes: 461\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "input_file = \"embedding_new_green/untreated/image_emd.tsv\"\n",
    "unique_genes = set()\n",
    "with open(input_file, \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    next(reader) # skip header\n",
    "    for row in reader:\n",
    "        gene_id = row[0]\n",
    "        unique_genes.add(gene_id)\n",
    "print(f\"Number of unique genes: {len(unique_genes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "23c71fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating hierarchy: 15it [00:00, 91.56it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hnguye24/.conda/envs/yolo7/lib/python3.10/site-packages/cellmaps_generate_hierarchy/runner.py:623: UserWarning: Layout disabled due to incompatibilities with HCX format\n",
      "  warnings.warn(\"Layout disabled due to incompatibilities with HCX format\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cellmaps_generate_hierarchy.ppi import CosineSimilarityPPIGenerator\n",
    "from cellmaps_generate_hierarchy.hierarchy import CDAPSHiDeFHierarchyGenerator\n",
    "from cellmaps_generate_hierarchy.maturehierarchy import HiDeFHierarchyRefiner\n",
    "from cellmaps_generate_hierarchy.hcx import HCXFromCDAPSCXHierarchy\n",
    "from cellmaps_generate_hierarchy.runner import CellmapsGenerateHierarchy\n",
    "\n",
    "inputdir = '3_new_green.coembedding_untreated'\n",
    "outdir = '5.2_new_green_hierarchy_untreated'\n",
    "ppigen = CosineSimilarityPPIGenerator(embeddingdirs=[inputdir])\n",
    "\n",
    "refiner = HiDeFHierarchyRefiner()\n",
    "\n",
    "converter = HCXFromCDAPSCXHierarchy()\n",
    "\n",
    "hiergen = CDAPSHiDeFHierarchyGenerator(refiner=refiner,\n",
    "                                       hcxconverter=converter)\n",
    "\n",
    "x = CellmapsGenerateHierarchy(outdir=outdir,\n",
    "                              inputdirs=inputdir,\n",
    "                              ppigen=ppigen,\n",
    "                              hiergen=hiergen)\n",
    "x.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadbd1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ndex2\n",
    "from ndex2.cx2 import RawCX2NetworkFactory\n",
    "from cellmaps_generate_hierarchy.ndexupload import NDExHierarchyUploader\n",
    "\n",
    "#Specify NDEx server\n",
    "ndexserver = 'public.ndexbio.org'\n",
    "ndexuser = ''\n",
    "ndexpassword = ''\n",
    "    \n",
    "# Specify paths to hierarchy and its parent (you can find example files in examples directory in cellmaps_generate_hierarchy_repo)\n",
    "hierarchy_path = './5.2_new_green_hierarchy_untreated/hierarchy.cx2'\n",
    "parent_network_path = './5.2_new_green_hierarchy_untreated/hierarchy_parent.cx2'\n",
    "\n",
    "# Load the hierarchy and parent network CX2 files into network objects\n",
    "factory = RawCX2NetworkFactory()\n",
    "hierarchy_network = factory.get_cx2network(hierarchy_path)\n",
    "parent_network = factory.get_cx2network(parent_network_path)\n",
    "\n",
    "# Initialize NDExHierarchyUploader with the specified NDEx server and credentials\n",
    "uploader = NDExHierarchyUploader(ndexserver, ndexuser, ndexpassword, visibility=True)\n",
    "\n",
    "# Upload the hierarchy and parent network to NDEx\n",
    "parent_uuid, parenturl, hierarchy_uuid, hierarchyurl = uploader.save_hierarchy_and_parent_network(hierarchy_network, parent_network)\n",
    "\n",
    "print(f\"Parent network UUID is {parent_uuid} and its URL in NDEx is {parenturl}\")\n",
    "print(f\"Hierarchy network UUID is {hierarchy_uuid} and its URL in NDEx is {hierarchyurl}\")\n",
    "\n",
    "# # Another option is to just specify the directory where the files are placed\n",
    "# _, _, _, hierarchyurl = uploader.upload_hierary_and_parent_network_from_files('./examples/')\n",
    "# print(f'Hierarchy uploaded. To view the hierarchy, paste this URL in your browser: {hierarchyurl}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c9d74e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir embedding_new_green/vorinostat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6ae50da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp embedding_old_green/vorinostat/image_emd.tsv outputs_green/tmp/vorinostat_image_emd_old.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "195f6dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp outputs_green/vorinostat_image_emd.tsv outputs_green/tmp/vorinostat_image_emd.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "19c4dd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Saved compact names like 'B2AI_3_untreated_C2_R1_z01' → output_compact.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Open input file and write to output file\n",
    "with open(\"outputs_green/tmp/manifest_vorinstat_step1.csv\", \"r\") as f_in, \\\n",
    "     open(\"outputs_green/tmp/manifest_vorinstat_step2.csv\", \"w\") as f_out:\n",
    "    \n",
    "    for i, line in enumerate(f_in, start=1):\n",
    "        if i == 1:  # skip header line\n",
    "            continue\n",
    "        line = line.strip()\n",
    "        # Match compact name pattern: B2AI_*_z##\n",
    "        match = re.search(r\"(B2AI_[^/]*?_z\\d{2})\", line)\n",
    "        if match:\n",
    "            compact = match.group(1)\n",
    "            f_out.write(compact + \"\\n\")\n",
    "\n",
    "print(\"Done! Saved compact names like 'B2AI_3_untreated_C2_R1_z01' → output_compact.tsv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1f97bf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done! Cleaned file saved to outputs_green/tmp/vorinostat_image_emd_step2.tsv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "input_file = \"outputs_green/tmp/vorinostat_image_emd_step1.tsv\"\n",
    "output_file = \"outputs_green/tmp/vorinostat_image_emd_step2.tsv\"\n",
    "\n",
    "with open(input_file, \"r\") as f_in, open(output_file, \"w\", newline=\"\") as f_out:\n",
    "    reader = csv.reader(f_in, delimiter=\"\\t\")\n",
    "    writer = csv.writer(f_out, delimiter=\"\\t\")\n",
    "\n",
    "    header = next(reader)\n",
    "    writer.writerow([\"id_trimmed\", *header[1:]])  # replace first column name\n",
    "\n",
    "    for row in reader:\n",
    "        image_id = row[0]\n",
    "        # remove prefix and suffix\n",
    "        trimmed_id = re.sub(r\"^vorinostat__|_green\\.png$\", \"\", image_id)\n",
    "        writer.writerow([trimmed_id, *row[1:]])\n",
    "\n",
    "print(f\"✅ Done! Cleaned file saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "85f62456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved updated TSV with gene names to outputs_green/tmp/vorinostat_image_emd_step2_with_gene.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load manifest (dictionary)\n",
    "manifest_df = pd.read_csv(\"outputs_green/tmp/manifest_vorinstat_step2.csv\")\n",
    "id_to_gene = dict(zip(manifest_df.iloc[:,0], manifest_df.iloc[:,1]))  # first col = ID, second col = Gene\n",
    "\n",
    "# Load TSV file\n",
    "tsv_df = pd.read_csv(\"outputs_green/tmp/vorinostat_image_emd_step2.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Insert gene column by mapping\n",
    "tsv_df.insert(1, \"Gene\", tsv_df.iloc[:,0].map(id_to_gene))\n",
    "\n",
    "# Save new file\n",
    "output_file = \"outputs_green/tmp/vorinostat_image_emd_step2_with_gene.tsv\"\n",
    "tsv_df.to_csv(output_file, sep=\"\\t\", index=False)\n",
    "\n",
    "print(f\"Saved updated TSV with gene names to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ef3b6404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean values saved to: outputs_green/tmp/vorinostat_image_emd_m_means.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load TSV file\n",
    "input_file = \"outputs_green/tmp/vorinostat_image_emd_m.tsv\"   # replace with your filename\n",
    "df = pd.read_csv(input_file, sep=\"\\t\")\n",
    "\n",
    "# Step 2: Compute mean per gene (assumes first column is \"id\" or \"Gene\")\n",
    "mean_df = df.groupby(df.columns[0]).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Step 3: Save to a new file\n",
    "output_file = \"outputs_green/tmp/vorinostat_image_emd_m_means.tsv\"\n",
    "mean_df.to_csv(output_file, sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"Mean values saved to:\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5b24fc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Comparison finished → resultst\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load both files (TSV format)\n",
    "file1 = pd.read_csv(\"outputs_green/tmp/vorinostat_image_emd_m_means.tsv\", sep=\"\\t\", dtype=str)\n",
    "file2 = pd.read_csv(\"outputs_green/tmp/vorinostat_image_emd_old.tsv\", sep=\"\\t\", dtype=str)\n",
    "\n",
    "# Extract the first column (assuming it's named 'id' or just the first column)\n",
    "col1_file1 = file1.iloc[:, 0]\n",
    "col1_file2 = file2.iloc[:, 0]\n",
    "\n",
    "# Find common and different IDs\n",
    "common_ids = set(col1_file1).intersection(set(col1_file2))\n",
    "only_in_file1 = set(col1_file1) - set(col1_file2)\n",
    "only_in_file2 = set(col1_file2) - set(col1_file1)\n",
    "\n",
    "# Save results\n",
    "with open(\"outputs_green/tmp/compare_vorinostat_v1.txt\", \"w\") as f:\n",
    "    f.write(\"✅ Common IDs: {}\\n\\n\".format(len(common_ids)))\n",
    "    f.write(\"\\n\".join(sorted(common_ids)))\n",
    "    f.write(\"\\n\\n❌ Only in file1 ({}):\\n\".format(len(only_in_file1)))\n",
    "    f.write(\"\\n\".join(sorted(only_in_file1)))\n",
    "    f.write(\"\\n\\n❌ Only in file2 ({}):\\n\".format(len(only_in_file2)))\n",
    "    f.write(\"\\n\".join(sorted(only_in_file2)))\n",
    "\n",
    "print(\"✅ Comparison finished → resultst\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "018c23bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Comparison finished → resultst\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load both files (TSV format)\n",
    "file1 = pd.read_csv(\"outputs_green/tmp/vorinostat_image_emd_m_means3.tsv\", sep=\"\\t\", dtype=str)\n",
    "file2 = pd.read_csv(\"outputs_green/tmp/vorinostat_image_emd_old.tsv\", sep=\"\\t\", dtype=str)\n",
    "\n",
    "# Extract the first column (assuming it's named 'id' or just the first column)\n",
    "col1_file1 = file1.iloc[:, 0]\n",
    "col1_file2 = file2.iloc[:, 0]\n",
    "\n",
    "# Find common and different IDs\n",
    "common_ids = set(col1_file1).intersection(set(col1_file2))\n",
    "only_in_file1 = set(col1_file1) - set(col1_file2)\n",
    "only_in_file2 = set(col1_file2) - set(col1_file1)\n",
    "\n",
    "# Save results\n",
    "with open(\"outputs_green/tmp/compare_vorinostat_v3.txt\", \"w\") as f:\n",
    "    f.write(\"✅ Common IDs: {}\\n\\n\".format(len(common_ids)))\n",
    "    f.write(\"\\n\".join(sorted(common_ids)))\n",
    "    f.write(\"\\n\\n❌ Only in file1 ({}):\\n\".format(len(only_in_file1)))\n",
    "    f.write(\"\\n\".join(sorted(only_in_file1)))\n",
    "    f.write(\"\\n\\n❌ Only in file2 ({}):\\n\".format(len(only_in_file2)))\n",
    "    f.write(\"\\n\".join(sorted(only_in_file2)))\n",
    "\n",
    "print(\"✅ Comparison finished → resultst\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4942db1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean values saved to: outputs_green/tmp/vorinostat_image_emd_m_means3.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load TSV file\n",
    "input_file = \"outputs_green/tmp/vorinostat_image_emd_m_means3.tsv\"   # replace with your filename\n",
    "df = pd.read_csv(input_file, sep=\"\\t\")\n",
    "\n",
    "# Step 2: Compute mean per gene (assumes first column is \"id\" or \"Gene\")\n",
    "mean_df = df.groupby(df.columns[0]).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Step 3: Save to a new file\n",
    "output_file = \"outputs_green/tmp/vorinostat_image_emd_m_means3.tsv\"\n",
    "mean_df.to_csv(output_file, sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"Mean values saved to:\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "837987f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp outputs_green/tmp/vorinostat_image_emd_m_means3.tsv embedding_new_green/vorinostat/image_emd.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1481d2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving embedding: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.04210638999938965 seconds\n",
      "Jaccard graph constructed in 1.1110906600952148 seconds\n",
      "Wrote graph to binary file in 0.004410505294799805 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.666489\n",
      "After 3 runs, maximum modularity is Q = 0.667549\n",
      "Louvain completed 23 runs in 0.1409904956817627 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.4385955333709717 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.03179216384887695 seconds\n",
      "Jaccard graph constructed in 1.0932769775390625 seconds\n",
      "Wrote graph to binary file in 0.002145051956176758 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.586144\n",
      "After 7 runs, maximum modularity is Q = 0.588308\n",
      "Louvain completed 27 runs in 0.11295485496520996 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.3973941802978516 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.018528223037719727 seconds\n",
      "Jaccard graph constructed in 1.1060090065002441 seconds\n",
      "Wrote graph to binary file in 0.0015828609466552734 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.48769\n",
      "After 2 runs, maximum modularity is Q = 0.492143\n",
      "Louvain completed 22 runs in 0.10350537300109863 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.366379737854004 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.12079143524169922 seconds\n",
      "Jaccard graph constructed in 1.0756556987762451 seconds\n",
      "Wrote graph to binary file in 0.0027642250061035156 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.549739\n",
      "Louvain completed 21 runs in 0.08055758476257324 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.290048360824585 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.015558242797851562 seconds\n",
      "Jaccard graph constructed in 1.056525468826294 seconds\n",
      "Wrote graph to binary file in 0.001996278762817383 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.690324\n",
      "Louvain completed 21 runs in 0.08035397529602051 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.206495761871338 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.018827438354492188 seconds\n",
      "Jaccard graph constructed in 1.0690767765045166 seconds\n",
      "Wrote graph to binary file in 0.0021893978118896484 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.735253\n",
      "Louvain completed 21 runs in 0.07749414443969727 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.2173993587493896 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.025485992431640625 seconds\n",
      "Jaccard graph constructed in 1.07655930519104 seconds\n",
      "Wrote graph to binary file in 0.001432657241821289 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.700084\n",
      "Louvain completed 21 runs in 0.07907319068908691 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.251976728439331 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.01735973358154297 seconds\n",
      "Jaccard graph constructed in 1.0583324432373047 seconds\n",
      "Wrote graph to binary file in 0.0021076202392578125 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.749689\n",
      "Louvain completed 21 runs in 0.0784459114074707 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.206514358520508 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving embedding: 97it [00:28,  3.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell map vorinostat\n",
    "\n",
    "from cellmaps_coembedding.runner import MuseCoEmbeddingGenerator\n",
    "from cellmaps_coembedding.runner import CellmapsCoEmbedder\n",
    "\n",
    "ppi_embeddingdir = '2.ppi_embedding'\n",
    "image_embeddingdir = 'embedding_new_green/vorinostat'\n",
    "outdir = '3_new_green.coembedding_vorinostat'\n",
    "gen = MuseCoEmbeddingGenerator(ppi_embeddingdir=ppi_embeddingdir,\n",
    "                               image_embeddingdir=image_embeddingdir,\n",
    "                               outdir=os.path.abspath(outdir))\n",
    "\n",
    "x = CellmapsCoEmbedder(outdir=outdir,\n",
    "                      inputdirs=[ppi_embeddingdir, image_embeddingdir],\n",
    "                      embedding_generator=gen)\n",
    "x.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e2ffa4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "input_file = \"embedding_new_green/vorinostat/image_emd.tsv\"\n",
    "# Store embeddings per gene\n",
    "data = defaultdict(list)\n",
    "# Read the original file\n",
    "with open(input_file, \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    header = next(reader) # store header\n",
    "    for row in reader:\n",
    "        gene_id = row[0]\n",
    "        embedding = list(map(float, row[1:]))\n",
    "        data[gene_id].append(embedding)\n",
    "# Compute mean and overwrite the same file\n",
    "with open(input_file, \"w\", newline='') as out:\n",
    "    writer = csv.writer(out, delimiter='\\t')\n",
    "    writer.writerow([\"id\"] + header[1:]) # write header back\n",
    "    for gene_id, vectors in data.items():\n",
    "        arr = np.array(vectors)\n",
    "        mean_vector = np.mean(arr, axis=0)\n",
    "        writer.writerow([gene_id] + mean_vector.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "86780780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique genes: 461\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "input_file = \"embedding_new_green/vorinostat/image_emd.tsv\"\n",
    "unique_genes = set()\n",
    "with open(input_file, \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    next(reader) # skip header\n",
    "    for row in reader:\n",
    "        gene_id = row[0]\n",
    "        unique_genes.add(gene_id)\n",
    "print(f\"Number of unique genes: {len(unique_genes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "245d3c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating hierarchy: 15it [00:00, 96.52it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hnguye24/.conda/envs/yolo7/lib/python3.10/site-packages/cellmaps_generate_hierarchy/runner.py:623: UserWarning: Layout disabled due to incompatibilities with HCX format\n",
      "  warnings.warn(\"Layout disabled due to incompatibilities with HCX format\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cellmaps_generate_hierarchy.ppi import CosineSimilarityPPIGenerator\n",
    "from cellmaps_generate_hierarchy.hierarchy import CDAPSHiDeFHierarchyGenerator\n",
    "from cellmaps_generate_hierarchy.maturehierarchy import HiDeFHierarchyRefiner\n",
    "from cellmaps_generate_hierarchy.hcx import HCXFromCDAPSCXHierarchy\n",
    "from cellmaps_generate_hierarchy.runner import CellmapsGenerateHierarchy\n",
    "\n",
    "inputdir = '3_new_green.coembedding_vorinostat'\n",
    "outdir = '5.2_new_green_hierarchy_vorinostat'\n",
    "ppigen = CosineSimilarityPPIGenerator(embeddingdirs=[inputdir])\n",
    "\n",
    "refiner = HiDeFHierarchyRefiner()\n",
    "\n",
    "converter = HCXFromCDAPSCXHierarchy()\n",
    "\n",
    "hiergen = CDAPSHiDeFHierarchyGenerator(refiner=refiner,\n",
    "                                       hcxconverter=converter)\n",
    "\n",
    "x = CellmapsGenerateHierarchy(outdir=outdir,\n",
    "                              inputdirs=inputdir,\n",
    "                              ppigen=ppigen,\n",
    "                              hiergen=hiergen)\n",
    "x.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f7d04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ndex2\n",
    "from ndex2.cx2 import RawCX2NetworkFactory\n",
    "from cellmaps_generate_hierarchy.ndexupload import NDExHierarchyUploader\n",
    "\n",
    "#Specify NDEx server\n",
    "ndexserver = 'public.ndexbio.org'\n",
    "ndexuser = ''\n",
    "ndexpassword = ''\n",
    "    \n",
    "# Specify paths to hierarchy and its parent (you can find example files in examples directory in cellmaps_generate_hierarchy_repo)\n",
    "hierarchy_path = './5.2_new_green_hierarchy_vorinostat/hierarchy.cx2'\n",
    "parent_network_path = './5.2_new_green_hierarchy_vorinostat/hierarchy_parent.cx2'\n",
    "\n",
    "# Load the hierarchy and parent network CX2 files into network objects\n",
    "factory = RawCX2NetworkFactory()\n",
    "hierarchy_network = factory.get_cx2network(hierarchy_path)\n",
    "parent_network = factory.get_cx2network(parent_network_path)\n",
    "\n",
    "# Initialize NDExHierarchyUploader with the specified NDEx server and credentials\n",
    "uploader = NDExHierarchyUploader(ndexserver, ndexuser, ndexpassword, visibility=True)\n",
    "\n",
    "# Upload the hierarchy and parent network to NDEx\n",
    "parent_uuid, parenturl, hierarchy_uuid, hierarchyurl = uploader.save_hierarchy_and_parent_network(hierarchy_network, parent_network)\n",
    "\n",
    "print(f\"Parent network UUID is {parent_uuid} and its URL in NDEx is {parenturl}\")\n",
    "print(f\"Hierarchy network UUID is {hierarchy_uuid} and its URL in NDEx is {hierarchyurl}\")\n",
    "\n",
    "# # Another option is to just specify the directory where the files are placed\n",
    "# _, _, _, hierarchyurl = uploader.upload_hierary_and_parent_network_from_files('./examples/')\n",
    "# print(f'Hierarchy uploaded. To view the hierarchy, paste this URL in your browser: {hierarchyurl}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdb3e71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:.conda-yolo7]",
   "language": "python",
   "name": "conda-env-.conda-yolo7-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
