{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8914b649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from cellmaps_imagedownloader.runner import CellmapsImageDownloader\n",
    "from cellmaps_imagedownloader.runner import MultiProcessImageDownloader\n",
    "from cellmaps_imagedownloader.gene import ImageGeneNodeAttributeGenerator as IGen \n",
    "from cellmaps_imagedownloader.proteinatlas import ProteinAtlasReader, ProteinAtlasImageUrlReader, ImageDownloadTupleGenerator\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "#import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import json\n",
    "from collections import Counter\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c19e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a34881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"data_green\"\n",
    "# CHANNELS = [\"blue\", \"green\", \"red\", \"yellow\"]\n",
    "CHANNELS = [\"green\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "116ab2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_image_paths(base_path=BASE_PATH):\n",
    "    records = []\n",
    "    for treatment_folder in os.listdir(base_path):\n",
    "        treatment_path = os.path.join(base_path, treatment_folder)\n",
    "        if not os.path.isdir(treatment_path):\n",
    "            continue\n",
    "\n",
    "        treatment = treatment_folder.split(\"-\")[-1].lower()\n",
    "\n",
    "        image_dict = {}\n",
    "        for channel in CHANNELS:\n",
    "            channel_path = os.path.join(treatment_path, channel)\n",
    "            for img_path in glob(os.path.join(channel_path, \"*.jpg\")):\n",
    "                # Extract base ID (strip _blue, _red, etc.)\n",
    "                basename = os.path.basename(img_path).replace(f\"_{channel}.jpg\", \"\")\n",
    "                image_dict.setdefault(basename, {\"id\": basename, \"treatment\": treatment})\n",
    "                image_dict[basename][channel] = img_path\n",
    "\n",
    "        records.extend(image_dict.values())\n",
    "\n",
    "    return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3fd7e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rocrate_metadata_with_antibodies(base_path=BASE_PATH):\n",
    "    print('base path: ',base_path)\n",
    "    \n",
    "    metadata_records = []\n",
    "\n",
    "    for treatment_folder in os.listdir(base_path):\n",
    "        crate_path = os.path.join(base_path, treatment_folder, \"ro-crate-metadata.json\")\n",
    "        if not os.path.isfile(crate_path):\n",
    "            continue\n",
    "\n",
    "        with open(crate_path, \"r\") as f:\n",
    "            crate = json.load(f)\n",
    "\n",
    "        # --- Build antibody/stain index ---\n",
    "        antibody_index = {}\n",
    "        for entry in crate.get(\"@graph\", []):\n",
    "            if entry.get(\"@type\") == \"BioChemEntity\":\n",
    "                stain_id = entry[\"@id\"]\n",
    "                identifiers = entry.get(\"identifier\", [])\n",
    "                if isinstance(identifiers, dict):\n",
    "                    identifiers = [identifiers]\n",
    "\n",
    "                id_map = {i.get(\"name\"): i.get(\"value\") for i in identifiers}\n",
    "\n",
    "                antibody_index[stain_id] = {\n",
    "                    \"name\": entry.get(\"name\"),\n",
    "                    \"description\": entry.get(\"description\"),\n",
    "                    \"hpa_id\": id_map.get(\"HPA Antibody ID\"),\n",
    "                    \"ensembl\": id_map.get(\"ENSEMBL\"),\n",
    "                    \"uniprot\": id_map.get(\"Uniprot\"),\n",
    "                    \"pubchem\": id_map.get(\"PubChem\"),\n",
    "                    \"subcellular_location\": (\n",
    "                        entry.get(\"isLocatedInSubcellularLocation\", {}).get(\"name\")\n",
    "                        if isinstance(entry.get(\"isLocatedInSubcellularLocation\"), dict)\n",
    "                        else None\n",
    "                    )\n",
    "                }\n",
    "\n",
    "        # --- Process each dataset (image) entry ---\n",
    "        for entry in crate.get(\"@graph\", []):\n",
    "            if entry.get(\"@type\") != \"EVI:Dataset\":\n",
    "                continue\n",
    "\n",
    "            content_url = entry.get(\"contentUrl\", \"\")\n",
    "            filename = os.path.basename(content_url.replace(\"file://\", \"\")).strip(\"/\")\n",
    "            if not filename.endswith(\".jpg\"):\n",
    "                continue\n",
    "\n",
    "            base_id = filename.replace(\".jpg\", \"\").rsplit(\"_\", 1)[0]\n",
    "            channel = filename.replace(\".jpg\", \"\").rsplit(\"_\", 1)[-1].lower()\n",
    "\n",
    "            stain_ref = entry.get(\"usedStain\", {}).get(\"@id\", \"\")\n",
    "            stain_key = stain_ref.split(\"/\")[-1].replace(\"stain-\", \"\")\n",
    "            ab_meta = antibody_index.get(stain_ref, {})\n",
    "\n",
    "            metadata_records.append({\n",
    "                \"id\": base_id,\n",
    "                \"channel\": channel,\n",
    "                \"antibody_stain\": stain_key,\n",
    "                \"antibody_name\": ab_meta.get(\"name\"),\n",
    "                \"antibody_hpa_id\": ab_meta.get(\"hpa_id\"),\n",
    "                \"antibody_ensembl\": ab_meta.get(\"ensembl\"),\n",
    "                \"antibody_uniprot\": ab_meta.get(\"uniprot\"),\n",
    "                \"antibody_pubchem\": ab_meta.get(\"pubchem\"),\n",
    "                \"subcellular_location\": ab_meta.get(\"subcellular_location\"),\n",
    "                \"cell_line\": entry.get(\"usedCellLine\", {}).get(\"@id\", \"\").split(\"/\")[-1].replace(\"cell-line-\", \"\"),\n",
    "                \"treatment\": entry.get(\"usedTreatment\", {}).get(\"@id\", \"\").split(\"/\")[-1].replace(\"treatment-\", \"\"),\n",
    "                \"description\": entry.get(\"description\", \"\"),\n",
    "                \"filename\": filename\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(metadata_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3cca03d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_lookup_ensembl_symbols(ensembl_ids, batch_size=1000):\n",
    "    \"\"\"\n",
    "    Look up gene symbols from Ensembl using batched POST requests.\n",
    "    Returns a dict {ensembl_id: gene_symbol}\n",
    "    \"\"\"\n",
    "    url = \"https://rest.ensembl.org/lookup/id\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    id_to_symbol = {}\n",
    "\n",
    "    for i in range(0, len(ensembl_ids), batch_size):\n",
    "        batch = ensembl_ids[i:i + batch_size]\n",
    "        payload = {\"ids\": batch}\n",
    "        try:\n",
    "            response = requests.post(url, headers=headers, json=payload)\n",
    "            if response.status_code == 200:\n",
    "                results = response.json()\n",
    "                for eid, info in results.items():\n",
    "                    id_to_symbol[eid] = info.get(\"display_name\", None)\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Error {response.status_code}: {response.text}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Request failed for batch starting at {i}: {e}\")\n",
    "    \n",
    "    return id_to_symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b44704a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_multichannel_image(row):\n",
    "    \"\"\"\n",
    "    Loads a 4-channel immunofluorescence image from separate grayscale files.\n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): A row from df_images with keys: blue, green, red, yellow.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: H x W x 4 array with channels in the order [blue, green, red, yellow]\n",
    "    \"\"\"\n",
    "    img_channels = []\n",
    "#     for ch in [\"blue\", \"green\", \"red\", \"yellow\"]:\n",
    "    for ch in [\"green\"]:    \n",
    "        path = row[ch]\n",
    "        img = Image.open(path).convert(\"L\")  # Load as 8-bit grayscale\n",
    "        img_array = np.array(img)\n",
    "        img_channels.append(img_array)\n",
    "\n",
    "    stacked = np.stack(img_channels, axis=-1)  # Shape: H x W x 4\n",
    "    return stacked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80415f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summary_report(df_merged, n_jobs=4):\n",
    "    print(\"üß¨üî¨ CM4AI Immunofluorescence Dataset Summary\\n\" + \"=\"*45, flush=True)\n",
    "\n",
    "    # 1. Number of treatments\n",
    "    n_treatments = df_merged[\"treatment\"].nunique()\n",
    "    print(f\"\\nüíä Number of treatments: {n_treatments}\", flush=True)\n",
    "    for cond, count in df_merged[\"treatment\"].value_counts().items():\n",
    "        print(f\"  - {cond}: {count} image-channel combinations\", flush=True)\n",
    "\n",
    "    # 2. Number of samples (unique image IDs) per treatment\n",
    "    print(\"\\nüß™ Number of unique samples per treatment:\", flush=True)\n",
    "    samples_per_treatment = (\n",
    "        df_merged[[\"id\", \"treatment\"]]\n",
    "        .drop_duplicates()\n",
    "        .groupby(\"treatment\")\n",
    "        .size()\n",
    "    )\n",
    "    for cond, count in samples_per_treatment.items():\n",
    "        print(f\"  - {cond}: {count} samples\", flush=True)\n",
    "\n",
    "    # 3. Image size distribution (parallelized)\n",
    "    print(\"\\nüñº Image size distribution:\", flush=True)\n",
    "\n",
    "    # Reconstruct wide format for loading multichannel images\n",
    "    df_channels = df_merged[[\"id\", \"channel\", \"filepath\"]].drop_duplicates()\n",
    "    df_shapes = df_channels.pivot(index=\"id\", columns=\"channel\", values=\"filepath\").reset_index()\n",
    "    df_treatments = df_merged[[\"id\", \"treatment\"]].drop_duplicates()\n",
    "    df_shapes = df_shapes.merge(df_treatments, on=\"id\", how=\"left\")\n",
    "\n",
    "    def safe_load_shape(row):\n",
    "        try:\n",
    "            img = load_multichannel_image(row)\n",
    "            return img.shape[:2]\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è Error loading image for ID {row['id']}: {e}\", flush=True)\n",
    "            return None\n",
    "\n",
    "    print(\"üîÑ Computing image shapes in parallel...\", flush=True)\n",
    "    shapes = Parallel(n_jobs=n_jobs, backend=\"threading\")(\n",
    "        delayed(safe_load_shape)(row) for _, row in tqdm(df_shapes.iterrows(), total=len(df_shapes))\n",
    "    )\n",
    "    df_shapes[\"shape\"] = shapes\n",
    "    shape_counts = Counter([s for s in shapes if s is not None])\n",
    "    for shape, count in shape_counts.items():\n",
    "        print(f\"  - {shape[0]}x{shape[1]}: {count} composite/multi-channel images\", flush=True)\n",
    "\n",
    "    # 4. Green channel antibody diversity\n",
    "    green_df = df_merged[df_merged[\"channel\"] == \"green\"]\n",
    "    unique_green = sorted(set(green_df[\"antibody_hpa_id\"].dropna().tolist()))\n",
    "    print(f\"\\nüü© Number of unique antibodies in green channel (protein target): {len(unique_green)}\", flush=True)\n",
    "\n",
    "    # 5. Red, Blue, Yellow antibody/stain names with icons\n",
    "    print(\"\\nüéØ Antibodies/stains used in other channels:\", flush=True)\n",
    "\n",
    "#     channel_icons = {\n",
    "#         \"red\": \"üü•\",\n",
    "#         \"blue\": \"üü¶\",\n",
    "#         \"yellow\": \"üü®\"\n",
    "#     }\n",
    "\n",
    "#     for ch in [\"red\", \"blue\", \"yellow\"]:\n",
    "#         ch_df = df_merged[df_merged[\"channel\"] == ch]\n",
    "#         unique_ab = sorted(set(\n",
    "#             ch_df[\"antibody_hpa_id\"].dropna().tolist() +\n",
    "#             ch_df[\"antibody_name\"].dropna().tolist()\n",
    "#         ))\n",
    "#         icon = channel_icons.get(ch, \"üîπ\")\n",
    "#         print(f\"\\n  {icon} {ch.upper()} channel antibodies/stains ({len(unique_ab)}):\", flush=True)\n",
    "#         for ab in unique_ab:\n",
    "#             print(f\"    - {ab}\", flush=True)\n",
    "\n",
    "    print(\"\\n‚úÖ Summary complete.\\n\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5df82c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image_gene_node_attributes(df_merged, base_output_dir=\"data/raw\"):\n",
    "    print('save_image_gene_node')\n",
    "    # Filter to green channel (protein target)\n",
    "    df_green = df_merged[df_merged[\"channel\"] == \"green\"].copy()\n",
    "\n",
    "    # Normalize treatment label: \"control\" becomes \"untreated\"\n",
    "    df_green[\"treatment\"] = df_green[\"treatment\"].replace(\"control\", \"untreated\")\n",
    "\n",
    "    # Drop exact duplicates across key fields\n",
    "    df_green = df_green.drop_duplicates(subset=[\"id\", \"treatment\", \"antibody_hpa_id\", \"antibody_ensembl\"])\n",
    "\n",
    "    # Group by treatment\n",
    "    treatments = df_green[\"treatment\"].dropna().unique()\n",
    "\n",
    "    for treatment in treatments:\n",
    "        print(treatment)\n",
    "        \n",
    "        df_t = df_green[df_green[\"treatment\"] == treatment]\n",
    "\n",
    "        df_out = pd.DataFrame({\n",
    "            \"name\": df_t[\"antibody_name\"],\n",
    "            \"represents\": \"ensembl:\" + df_t[\"antibody_ensembl\"].fillna(\"\"),\n",
    "            \"ambiguous\": df_t[\"antibody_hpa_id\"],\n",
    "            \"antibody\": df_t[\"antibody_hpa_id\"],\n",
    "            \"filename\": df_t[\"id\"].astype(str) + \"_\",\n",
    "            \"imageurl\": \"no image url found\"\n",
    "        })\n",
    "\n",
    "        unique_ensembl_ids = (\n",
    "            df_out[\"represents\"]\n",
    "            .dropna()\n",
    "            .str.replace(\"ensembl:\", \"\", regex=False)\n",
    "            .loc[lambda s: s.str.match(r\"ENSG\\d+\")]  # keep only valid Ensembl Gene IDs\n",
    "            .unique()\n",
    "            .tolist()\n",
    "        )\n",
    "\n",
    "        ensembl_to_name = batch_lookup_ensembl_symbols(unique_ensembl_ids)\n",
    "\n",
    "        df_out[\"name\"] = (\n",
    "            df_out[\"represents\"]\n",
    "            .str.replace(\"ensembl:\", \"\", regex=False)\n",
    "            .map(ensembl_to_name)\n",
    "        )\n",
    "\n",
    "        df_out[\"name\"] = df_out[\"name\"].fillna(\"NEGATIVE\")\n",
    "\n",
    "        # Save to the appropriate treatment folder\n",
    "        treatment_folder = os.path.join(base_output_dir, treatment)\n",
    "        os.makedirs(treatment_folder, exist_ok=True)\n",
    "\n",
    "        out_path = os.path.join(treatment_folder, \"1_image_gene_node_attributes.tsv\")\n",
    "        df_out.to_csv(out_path, sep=\"\\t\", index=False)\n",
    "\n",
    "        print(f\"‚úÖ Saved: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89010645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>treatment</th>\n",
       "      <th>green</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B2AI_2_untreated_D7_R12_z00</td>\n",
       "      <td>untreated</td>\n",
       "      <td>data_green/untreated/green/B2AI_2_untreated_D7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B2AI_2_untreated_F6_R5_z01</td>\n",
       "      <td>untreated</td>\n",
       "      <td>data_green/untreated/green/B2AI_2_untreated_F6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B2AI_5_untreated_B3_R12_z00</td>\n",
       "      <td>untreated</td>\n",
       "      <td>data_green/untreated/green/B2AI_5_untreated_B3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B2AI_4_untreated_F8_R8_z02</td>\n",
       "      <td>untreated</td>\n",
       "      <td>data_green/untreated/green/B2AI_4_untreated_F8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B2AI_5_untreated_F12_R3_z01</td>\n",
       "      <td>untreated</td>\n",
       "      <td>data_green/untreated/green/B2AI_5_untreated_F1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12855</th>\n",
       "      <td>B2AI_3_Paclitaxel_G6_R5_z00</td>\n",
       "      <td>paclitaxel</td>\n",
       "      <td>data_green/paclitaxel/green/B2AI_3_Paclitaxel_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12856</th>\n",
       "      <td>B2AI_2_Paclitaxel_H11_R16_z00</td>\n",
       "      <td>paclitaxel</td>\n",
       "      <td>data_green/paclitaxel/green/B2AI_2_Paclitaxel_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12857</th>\n",
       "      <td>B2AI_5_Paclitaxel_D3_R2_z01</td>\n",
       "      <td>paclitaxel</td>\n",
       "      <td>data_green/paclitaxel/green/B2AI_5_Paclitaxel_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12858</th>\n",
       "      <td>B2AI_3_Paclitaxel_D12_R14_z00</td>\n",
       "      <td>paclitaxel</td>\n",
       "      <td>data_green/paclitaxel/green/B2AI_3_Paclitaxel_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12859</th>\n",
       "      <td>B2AI_4_Paclitaxel_F8_R1_z01</td>\n",
       "      <td>paclitaxel</td>\n",
       "      <td>data_green/paclitaxel/green/B2AI_4_Paclitaxel_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12860 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id   treatment  \\\n",
       "0        B2AI_2_untreated_D7_R12_z00   untreated   \n",
       "1         B2AI_2_untreated_F6_R5_z01   untreated   \n",
       "2        B2AI_5_untreated_B3_R12_z00   untreated   \n",
       "3         B2AI_4_untreated_F8_R8_z02   untreated   \n",
       "4        B2AI_5_untreated_F12_R3_z01   untreated   \n",
       "...                              ...         ...   \n",
       "12855    B2AI_3_Paclitaxel_G6_R5_z00  paclitaxel   \n",
       "12856  B2AI_2_Paclitaxel_H11_R16_z00  paclitaxel   \n",
       "12857    B2AI_5_Paclitaxel_D3_R2_z01  paclitaxel   \n",
       "12858  B2AI_3_Paclitaxel_D12_R14_z00  paclitaxel   \n",
       "12859    B2AI_4_Paclitaxel_F8_R1_z01  paclitaxel   \n",
       "\n",
       "                                                   green  \n",
       "0      data_green/untreated/green/B2AI_2_untreated_D7...  \n",
       "1      data_green/untreated/green/B2AI_2_untreated_F6...  \n",
       "2      data_green/untreated/green/B2AI_5_untreated_B3...  \n",
       "3      data_green/untreated/green/B2AI_4_untreated_F8...  \n",
       "4      data_green/untreated/green/B2AI_5_untreated_F1...  \n",
       "...                                                  ...  \n",
       "12855  data_green/paclitaxel/green/B2AI_3_Paclitaxel_...  \n",
       "12856  data_green/paclitaxel/green/B2AI_2_Paclitaxel_...  \n",
       "12857  data_green/paclitaxel/green/B2AI_5_Paclitaxel_...  \n",
       "12858  data_green/paclitaxel/green/B2AI_3_Paclitaxel_...  \n",
       "12859  data_green/paclitaxel/green/B2AI_4_Paclitaxel_...  \n",
       "\n",
       "[12860 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_images = collect_image_paths()\n",
    "df_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee03447a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>treatment</th>\n",
       "      <th>green</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3880</th>\n",
       "      <td>B2AI_3_untreated_C2_R3_z01</td>\n",
       "      <td>untreated</td>\n",
       "      <td>data_green/untreated/green/B2AI_3_untreated_C2_R3_z01_green.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12743</th>\n",
       "      <td>B2AI_3_untreated_C2_R3_z01</td>\n",
       "      <td>paclitaxel</td>\n",
       "      <td>data_green/paclitaxel/green/B2AI_3_untreated_C2_R3_z01_green.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               id   treatment  \\\n",
       "3880   B2AI_3_untreated_C2_R3_z01   untreated   \n",
       "12743  B2AI_3_untreated_C2_R3_z01  paclitaxel   \n",
       "\n",
       "                                                                  green  \n",
       "3880    data_green/untreated/green/B2AI_3_untreated_C2_R3_z01_green.jpg  \n",
       "12743  data_green/paclitaxel/green/B2AI_3_untreated_C2_R3_z01_green.jpg  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_colwidth', None):\n",
    "    display(df_images[df_images.duplicated(subset=\"id\", keep=False)].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f49c7978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base path:  data_green\n",
      "                                  id channel  \\\n",
      "0        B2AI_2_untreated_D7_R12_z00   green   \n",
      "1         B2AI_2_untreated_F6_R5_z01   green   \n",
      "2        B2AI_5_untreated_B3_R12_z00   green   \n",
      "3         B2AI_4_untreated_F8_R8_z02   green   \n",
      "4        B2AI_5_untreated_F12_R3_z01   green   \n",
      "...                              ...     ...   \n",
      "12855    B2AI_3_Paclitaxel_G6_R5_z00   green   \n",
      "12856  B2AI_2_Paclitaxel_H11_R16_z00   green   \n",
      "12857    B2AI_5_Paclitaxel_D3_R2_z01   green   \n",
      "12858  B2AI_3_Paclitaxel_D12_R14_z00   green   \n",
      "12859    B2AI_4_Paclitaxel_F8_R1_z01   green   \n",
      "\n",
      "                                                filepath  \\\n",
      "0      data_green/untreated/green/B2AI_2_untreated_D7...   \n",
      "1      data_green/untreated/green/B2AI_2_untreated_F6...   \n",
      "2      data_green/untreated/green/B2AI_5_untreated_B3...   \n",
      "3      data_green/untreated/green/B2AI_4_untreated_F8...   \n",
      "4      data_green/untreated/green/B2AI_5_untreated_F1...   \n",
      "...                                                  ...   \n",
      "12855  data_green/paclitaxel/green/B2AI_3_Paclitaxel_...   \n",
      "12856  data_green/paclitaxel/green/B2AI_2_Paclitaxel_...   \n",
      "12857  data_green/paclitaxel/green/B2AI_5_Paclitaxel_...   \n",
      "12858  data_green/paclitaxel/green/B2AI_3_Paclitaxel_...   \n",
      "12859  data_green/paclitaxel/green/B2AI_4_Paclitaxel_...   \n",
      "\n",
      "                antibody_stain    antibody_name antibody_hpa_id  \\\n",
      "0      b2ai-antibody-HPA041143  Stain HPA041143       HPA041143   \n",
      "1      b2ai-antibody-HPA036978  Stain HPA036978       HPA036978   \n",
      "2      b2ai-antibody-HPA018987  Stain HPA018987       HPA018987   \n",
      "3      b2ai-antibody-HPA045462  Stain HPA045462       HPA045462   \n",
      "4      b2ai-antibody-HPA073760  Stain HPA073760       HPA073760   \n",
      "...                        ...              ...             ...   \n",
      "12855  b2ai-antibody-HPA038884  Stain HPA038884       HPA038884   \n",
      "12856  b2ai-antibody-HPA070486  Stain HPA070486       HPA070486   \n",
      "12857  b2ai-antibody-HPA019006  Stain HPA019006       HPA019006   \n",
      "12858  b2ai-antibody-HPA075204  Stain HPA075204       HPA075204   \n",
      "12859  b2ai-antibody-HPA045462  Stain HPA045462       HPA045462   \n",
      "\n",
      "      antibody_ensembl antibody_uniprot antibody_pubchem subcellular_location  \\\n",
      "0      ENSG00000177106           Q9H6S3             None                 None   \n",
      "1      ENSG00000247077           Q96HS1             None                 None   \n",
      "2      ENSG00000159692           Q13363             None                 None   \n",
      "3      ENSG00000065357           P23743             None                 None   \n",
      "4      ENSG00000131373           Q9UJ83             None                 None   \n",
      "...                ...              ...              ...                  ...   \n",
      "12855  ENSG00000137693           P46937             None                 None   \n",
      "12856  ENSG00000179841           P24588             None                 None   \n",
      "12857  ENSG00000072778           P49748             None                 None   \n",
      "12858  ENSG00000023171           Q3KR37             None                 None   \n",
      "12859  ENSG00000065357           P23743             None                 None   \n",
      "\n",
      "        cell_line   treatment  \\\n",
      "0      MDA-MB-468     control   \n",
      "1      MDA-MB-468     control   \n",
      "2      MDA-MB-468     control   \n",
      "3      MDA-MB-468     control   \n",
      "4      MDA-MB-468     control   \n",
      "...           ...         ...   \n",
      "12855  MDA-MB-468  paclitaxel   \n",
      "12856  MDA-MB-468  paclitaxel   \n",
      "12857  MDA-MB-468  paclitaxel   \n",
      "12858  MDA-MB-468  paclitaxel   \n",
      "12859  MDA-MB-468  paclitaxel   \n",
      "\n",
      "                                             description  \\\n",
      "0      This immunoflouresence image was taken of a we...   \n",
      "1      This immunoflouresence image was taken of a we...   \n",
      "2      This immunoflouresence image was taken of a we...   \n",
      "3      This immunoflouresence image was taken of a we...   \n",
      "4      This immunoflouresence image was taken of a we...   \n",
      "...                                                  ...   \n",
      "12855  This immunoflouresence image was taken of a we...   \n",
      "12856  This immunoflouresence image was taken of a we...   \n",
      "12857  This immunoflouresence image was taken of a we...   \n",
      "12858  This immunoflouresence image was taken of a we...   \n",
      "12859  This immunoflouresence image was taken of a we...   \n",
      "\n",
      "                                      filename  \n",
      "0        B2AI_2_untreated_D7_R12_z00_green.jpg  \n",
      "1         B2AI_2_untreated_F6_R5_z01_green.jpg  \n",
      "2        B2AI_5_untreated_B3_R12_z00_green.jpg  \n",
      "3         B2AI_4_untreated_F8_R8_z02_green.jpg  \n",
      "4        B2AI_5_untreated_F12_R3_z01_green.jpg  \n",
      "...                                        ...  \n",
      "12855    B2AI_3_Paclitaxel_G6_R5_z00_green.jpg  \n",
      "12856  B2AI_2_Paclitaxel_H11_R16_z00_green.jpg  \n",
      "12857    B2AI_5_Paclitaxel_D3_R2_z01_green.jpg  \n",
      "12858  B2AI_3_Paclitaxel_D12_R14_z00_green.jpg  \n",
      "12859    B2AI_4_Paclitaxel_F8_R1_z01_green.jpg  \n",
      "\n",
      "[12860 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "df_meta = load_rocrate_metadata_with_antibodies()\n",
    "df_images_melted = df_images.melt(\n",
    "    id_vars=[\"id\"],  # remove \"treatment\" here\n",
    "#     value_vars=[\"blue\", \"green\", \"red\", \"yellow\"],\n",
    "    value_vars=[\"green\"],\n",
    "    var_name=\"channel\",\n",
    "    value_name=\"filepath\"\n",
    ")\n",
    "\n",
    "df_merged = df_images_melted.merge(df_meta, on=[\"id\", \"channel\"], how=\"left\")\n",
    "print(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de729d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_image_gene_node\n",
      "untreated\n",
      "‚úÖ Saved: data_green/untreated/1_image_gene_node_attributes.tsv\n",
      "vorinostat\n",
      "‚úÖ Saved: data_green/vorinostat/1_image_gene_node_attributes.tsv\n",
      "paclitaxel\n",
      "‚úÖ Saved: data_green/paclitaxel/1_image_gene_node_attributes.tsv\n"
     ]
    }
   ],
   "source": [
    "save_image_gene_node_attributes(df_merged, base_output_dir=BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3fed3443",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The project name for RO-Crate /data/user/home/hnguye24/cm4ai/data_green/untreated is missing from the metadata. Please provide a name to uphold FAIR principles. Execution will proceed without the  name.\n",
      "The organization name for RO-Crate /data/user/home/hnguye24/cm4ai/data_green/untreated is missing from the metadata. Please provide a name to uphold FAIR principles. Execution will proceed without the  name.\n",
      "Downloading external_crop512_focal_slov_hardlog_class_densenet121_dropout_i768_aug2_5folds_fold0_final.pth: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66.1M/66.1M [00:00<00:00, 80.6MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model: /data/user/home/hnguye24/cm4ai/embedding_old_green/untreated/model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3976/3976 [2:31:17<00:00,  2.28s/it]  \n",
      "The project name for RO-Crate /data/user/home/hnguye24/cm4ai/data_green/vorinostat is missing from the metadata. Please provide a name to uphold FAIR principles. Execution will proceed without the  name.\n",
      "The organization name for RO-Crate /data/user/home/hnguye24/cm4ai/data_green/vorinostat is missing from the metadata. Please provide a name to uphold FAIR principles. Execution will proceed without the  name.\n",
      "Downloading external_crop512_focal_slov_hardlog_class_densenet121_dropout_i768_aug2_5folds_fold0_final.pth: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66.1M/66.1M [00:00<00:00, 83.4MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model: /data/user/home/hnguye24/cm4ai/embedding_old_green/vorinostat/model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4462/4462 [1:25:05<00:00,  1.14s/it]  \n",
      "The project name for RO-Crate /data/user/home/hnguye24/cm4ai/data_green/paclitaxel is missing from the metadata. Please provide a name to uphold FAIR principles. Execution will proceed without the  name.\n",
      "The organization name for RO-Crate /data/user/home/hnguye24/cm4ai/data_green/paclitaxel is missing from the metadata. Please provide a name to uphold FAIR principles. Execution will proceed without the  name.\n",
      "Downloading external_crop512_focal_slov_hardlog_class_densenet121_dropout_i768_aug2_5folds_fold0_final.pth: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66.1M/66.1M [00:00<00:00, 85.9MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model: /data/user/home/hnguye24/cm4ai/embedding_old_green/paclitaxel/model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4422/4422 [36:21<00:00,  2.03it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from cellmaps_image_embedding.runner import DensenetEmbeddingGenerator\n",
    "from cellmaps_image_embedding.runner import CellmapsImageEmbedder\n",
    "\n",
    "input_base_path = \"data_green\"\n",
    "image_interim_base_path = \"pipeline_images\"\n",
    "embedding_base_path = \"embedding_old_green\"\n",
    "\n",
    "for treatment_folder in os.listdir(input_base_path):\n",
    "    input_path = os.path.join(input_base_path, treatment_folder)\n",
    "    if not os.path.isdir(input_path):\n",
    "        continue\n",
    "    manifest_path = os.path.join(input_path, \"manifest.csv\")\n",
    "    image_interim_path = os.path.join(image_interim_base_path, treatment_folder)\n",
    "    embedding_path = os.path.join(embedding_base_path, treatment_folder)\n",
    "\n",
    "    gen = DensenetEmbeddingGenerator(\n",
    "        input_path,\n",
    "        outdir=embedding_path,\n",
    "        model_path=\"https://github.com/CellProfiling/densenet/releases/download/v0.1.0/external_crop512_focal_slov_hardlog_class_densenet121_dropout_i768_aug2_5folds_fold0_final.pth\",\n",
    "        fold=1\n",
    "    )\n",
    "    embedder = CellmapsImageEmbedder(\n",
    "        outdir=embedding_path,\n",
    "        inputdir=input_path,\n",
    "        embedding_generator=gen,\n",
    "        name=f\"{treatment_folder} IF Embedding\",\n",
    "        organization_name=\"CM4AI\",\n",
    "        project_name=\"CM4AI IF Embedding Tutorial\"\n",
    "    )\n",
    "    embedder.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1441f5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean values saved to: embedding_old_green/vorinostat/gene_means.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load TSV file\n",
    "input_file = \"embedding_old_green/vorinostat/image_emd.tsv\"   # replace with your filename\n",
    "df = pd.read_csv(input_file, sep=\"\\t\")\n",
    "\n",
    "# Step 2: Compute mean per gene (assumes first column is \"id\" or \"Gene\")\n",
    "mean_df = df.groupby(df.columns[0]).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Step 3: Save to a new file\n",
    "output_file = \"embedding_old_green/vorinostat/gene_means.tsv\"\n",
    "mean_df.to_csv(output_file, sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"Mean values saved to:\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c24b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -r data/.ipynb_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c35efe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellmaps_ppi_embedding.runner import Node2VecEmbeddingGenerator\n",
    "from cellmaps_ppi_embedding.runner import CellMapsPPIEmbedder\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32be617",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputdir = '1.ppi_download'\n",
    "outdir = '2.ppi_embedding'\n",
    "gen = Node2VecEmbeddingGenerator(nx_network=nx.read_edgelist(CellMapsPPIEmbedder.get_apms_edgelist_file(inputdir),\n",
    "                                                             delimiter='\\t'))\n",
    "\n",
    "x =CellMapsPPIEmbedder(outdir=outdir,\n",
    "                       embedding_generator=gen,\n",
    "                      inputdir=inputdir)\n",
    "x.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b98aab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving embedding: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.25135207176208496 seconds\n",
      "Jaccard graph constructed in 1.012181282043457 seconds\n",
      "Wrote graph to binary file in 0.0030052661895751953 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.66654\n",
      "After 5 runs, maximum modularity is Q = 0.667759\n",
      "Louvain completed 25 runs in 0.1549065113067627 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.418247699737549 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.01608872413635254 seconds\n",
      "Jaccard graph constructed in 0.9773478507995605 seconds\n",
      "Wrote graph to binary file in 0.002326488494873047 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.688086\n",
      "Louvain completed 21 runs in 0.0819997787475586 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.0767061710357666 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.03568911552429199 seconds\n",
      "Jaccard graph constructed in 1.0928270816802979 seconds\n",
      "Wrote graph to binary file in 0.0027217864990234375 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.501385\n",
      "After 2 runs, maximum modularity is Q = 0.502805\n",
      "After 3 runs, maximum modularity is Q = 0.512153\n",
      "After 5 runs, maximum modularity is Q = 0.514759\n",
      "Louvain completed 25 runs in 0.11704111099243164 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.3549327850341797 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.027199745178222656 seconds\n",
      "Jaccard graph constructed in 1.065657138824463 seconds\n",
      "Wrote graph to binary file in 0.0016131401062011719 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.634744\n",
      "After 2 runs, maximum modularity is Q = 0.637906\n",
      "After 6 runs, maximum modularity is Q = 0.643188\n",
      "Louvain completed 26 runs in 0.11177802085876465 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.296065330505371 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.01659083366394043 seconds\n",
      "Jaccard graph constructed in 1.0213606357574463 seconds\n",
      "Wrote graph to binary file in 0.001674652099609375 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.665719\n",
      "Louvain completed 21 runs in 0.07760095596313477 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.2298378944396973 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.01629042625427246 seconds\n",
      "Jaccard graph constructed in 1.0946717262268066 seconds\n",
      "Wrote graph to binary file in 0.0013990402221679688 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.707324\n",
      "Louvain completed 21 runs in 0.07716917991638184 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.2012994289398193 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.015045642852783203 seconds\n",
      "Jaccard graph constructed in 1.0331857204437256 seconds\n",
      "Wrote graph to binary file in 0.0015704631805419922 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.671557\n",
      "Louvain completed 21 runs in 0.0785369873046875 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.2212822437286377 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.027632951736450195 seconds\n",
      "Jaccard graph constructed in 1.0340933799743652 seconds\n",
      "Wrote graph to binary file in 0.0017137527465820312 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.745473\n",
      "Louvain completed 21 runs in 0.07806277275085449 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.1509149074554443 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving embedding: 97it [00:34,  2.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell map paclitaxel\n",
    "\n",
    "from cellmaps_coembedding.runner import MuseCoEmbeddingGenerator\n",
    "from cellmaps_coembedding.runner import CellmapsCoEmbedder\n",
    "\n",
    "ppi_embeddingdir = '2.ppi_embedding'\n",
    "image_embeddingdir = 'embedding_old_green/vorinostat'\n",
    "outdir = '3_old_green.coembedding_vorinostat'\n",
    "gen = MuseCoEmbeddingGenerator(ppi_embeddingdir=ppi_embeddingdir,\n",
    "                               image_embeddingdir=image_embeddingdir,\n",
    "                               outdir=os.path.abspath(outdir))\n",
    "\n",
    "x = CellmapsCoEmbedder(outdir=outdir,\n",
    "                      inputdirs=[ppi_embeddingdir, image_embeddingdir],\n",
    "                      embedding_generator=gen)\n",
    "x.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "86d79d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "input_file = \"embedding_old_green/vorinostat/image_emd.tsv\"\n",
    "# Store embeddings per gene\n",
    "data = defaultdict(list)\n",
    "# Read the original file\n",
    "with open(input_file, \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    header = next(reader) # store header\n",
    "    for row in reader:\n",
    "        gene_id = row[0]\n",
    "        embedding = list(map(float, row[1:]))\n",
    "        data[gene_id].append(embedding)\n",
    "# Compute mean and overwrite the same file\n",
    "with open(input_file, \"w\", newline='') as out:\n",
    "    writer = csv.writer(out, delimiter='\\t')\n",
    "    writer.writerow([\"id\"] + header[1:]) # write header back\n",
    "    for gene_id, vectors in data.items():\n",
    "        arr = np.array(vectors)\n",
    "        mean_vector = np.mean(arr, axis=0)\n",
    "        writer.writerow([gene_id] + mean_vector.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b67cc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique genes: 461\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "input_file = \"embedding_old_green/vorinostat/image_emd.tsv\"\n",
    "unique_genes = set()\n",
    "with open(input_file, \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    next(reader) # skip header\n",
    "    for row in reader:\n",
    "        gene_id = row[0]\n",
    "        unique_genes.add(gene_id)\n",
    "print(f\"Number of unique genes: {len(unique_genes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d9eb00f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating hierarchy: 15it [00:00, 53.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/hnguye24/.conda/envs/yolo7/lib/python3.10/site-packages/cellmaps_generate_hierarchy/runner.py:623: UserWarning: Layout disabled due to incompatibilities with HCX format\n",
      "  warnings.warn(\"Layout disabled due to incompatibilities with HCX format\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cellmaps_generate_hierarchy.ppi import CosineSimilarityPPIGenerator\n",
    "from cellmaps_generate_hierarchy.hierarchy import CDAPSHiDeFHierarchyGenerator\n",
    "from cellmaps_generate_hierarchy.maturehierarchy import HiDeFHierarchyRefiner\n",
    "from cellmaps_generate_hierarchy.hcx import HCXFromCDAPSCXHierarchy\n",
    "from cellmaps_generate_hierarchy.runner import CellmapsGenerateHierarchy\n",
    "\n",
    "inputdir = '3_old_green.coembedding_vorinostat'\n",
    "outdir = '5.2_old_green_hierarchy_vorinostat'\n",
    "ppigen = CosineSimilarityPPIGenerator(embeddingdirs=[inputdir])\n",
    "\n",
    "refiner = HiDeFHierarchyRefiner()\n",
    "\n",
    "converter = HCXFromCDAPSCXHierarchy()\n",
    "\n",
    "hiergen = CDAPSHiDeFHierarchyGenerator(refiner=refiner,\n",
    "                                       hcxconverter=converter)\n",
    "\n",
    "x = CellmapsGenerateHierarchy(outdir=outdir,\n",
    "                              inputdirs=inputdir,\n",
    "                              ppigen=ppigen,\n",
    "                              hiergen=hiergen)\n",
    "x.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c7614059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent network UUID is 8b7f887a-911f-11f0-a218-005056ae3c32 and its URL in NDEx is https://www.ndexbio.org/viewer/networks/8b7f887a-911f-11f0-a218-005056ae3c32\n",
      "Hierarchy network UUID is 8b9c112c-911f-11f0-a218-005056ae3c32 and its URL in NDEx is https://www.ndexbio.org/viewer/networks/8b9c112c-911f-11f0-a218-005056ae3c32\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ndex2\n",
    "from ndex2.cx2 import RawCX2NetworkFactory\n",
    "from cellmaps_generate_hierarchy.ndexupload import NDExHierarchyUploader\n",
    "\n",
    "#Specify NDEx server\n",
    "ndexserver = 'public.ndexbio.org'\n",
    "ndexuser = ''\n",
    "ndexpassword = ''\n",
    "    \n",
    "# Specify paths to hierarchy and its parent (you can find example files in examples directory in cellmaps_generate_hierarchy_repo)\n",
    "hierarchy_path = './5.2_old_green_hierarchy_vorinostat/hierarchy.cx2'\n",
    "parent_network_path = './5.2_old_green_hierarchy_vorinostat/hierarchy_parent.cx2'\n",
    "\n",
    "# Load the hierarchy and parent network CX2 files into network objects\n",
    "factory = RawCX2NetworkFactory()\n",
    "hierarchy_network = factory.get_cx2network(hierarchy_path)\n",
    "parent_network = factory.get_cx2network(parent_network_path)\n",
    "\n",
    "# Initialize NDExHierarchyUploader with the specified NDEx server and credentials\n",
    "uploader = NDExHierarchyUploader(ndexserver, ndexuser, ndexpassword, visibility=True)\n",
    "\n",
    "# Upload the hierarchy and parent network to NDEx\n",
    "parent_uuid, parenturl, hierarchy_uuid, hierarchyurl = uploader.save_hierarchy_and_parent_network(hierarchy_network, parent_network)\n",
    "\n",
    "print(f\"Parent network UUID is {parent_uuid} and its URL in NDEx is {parenturl}\")\n",
    "print(f\"Hierarchy network UUID is {hierarchy_uuid} and its URL in NDEx is {hierarchyurl}\")\n",
    "\n",
    "# # Another option is to just specify the directory where the files are placed\n",
    "# _, _, _, hierarchyurl = uploader.upload_hierary_and_parent_network_from_files('./examples/')\n",
    "# print(f'Hierarchy uploaded. To view the hierarchy, paste this URL in your browser: {hierarchyurl}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f7b568a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean values saved to: embedding_old_green/untreated/gene_means.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load TSV file\n",
    "input_file = \"embedding_old_green/untreated/image_emd.tsv\"   # replace with your filename\n",
    "df = pd.read_csv(input_file, sep=\"\\t\")\n",
    "\n",
    "# Step 2: Compute mean per gene (assumes first column is \"id\" or \"Gene\")\n",
    "mean_df = df.groupby(df.columns[0]).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Step 3: Save to a new file\n",
    "output_file = \"embedding_old_green/untreated/gene_means.tsv\"\n",
    "mean_df.to_csv(output_file, sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"Mean values saved to:\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2f4eb0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files renamed successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Paths\n",
    "old_dir = \"embedding_old_green/untreated\"\n",
    "old_image = os.path.join(old_dir, \"image_emd.tsv\")\n",
    "new_image = os.path.join(old_dir, \"image_emd2.tsv\")\n",
    "gene_means = os.path.join(old_dir, \"gene_means.tsv\")\n",
    "new_gene_means = os.path.join(old_dir, \"image_emd.tsv\")\n",
    "\n",
    "# Rename image_emd.tsv ‚Üí image_emd2.tsv\n",
    "os.rename(old_image, new_image)\n",
    "\n",
    "# Rename gene_means.tsv ‚Üí image_emd.tsv\n",
    "os.rename(gene_means, new_gene_means)\n",
    "\n",
    "print(\"Files renamed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "61e4c1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving embedding: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.028494834899902344 seconds\n",
      "Jaccard graph constructed in 1.2302742004394531 seconds\n",
      "Wrote graph to binary file in 0.0028908252716064453 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.66567\n",
      "After 2 runs, maximum modularity is Q = 0.666853\n",
      "After 4 runs, maximum modularity is Q = 0.668028\n",
      "Louvain completed 24 runs in 0.10589838027954102 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.5843708515167236 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.02761077880859375 seconds\n",
      "Jaccard graph constructed in 1.2105543613433838 seconds\n",
      "Wrote graph to binary file in 0.001458883285522461 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.679937\n",
      "After 3 runs, maximum modularity is Q = 0.681284\n",
      "Louvain completed 23 runs in 0.09343242645263672 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.522735357284546 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.08619928359985352 seconds\n",
      "Jaccard graph constructed in 1.2923805713653564 seconds\n",
      "Wrote graph to binary file in 0.0015153884887695312 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.517133\n",
      "Louvain completed 21 runs in 0.08751201629638672 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.6967482566833496 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.017109394073486328 seconds\n",
      "Jaccard graph constructed in 1.2988708019256592 seconds\n",
      "Wrote graph to binary file in 0.00147247314453125 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.679508\n",
      "Louvain completed 21 runs in 0.07818770408630371 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.614079236984253 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.016220808029174805 seconds\n",
      "Jaccard graph constructed in 1.20894193649292 seconds\n",
      "Wrote graph to binary file in 0.0019826889038085938 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.646946\n",
      "After 2 runs, maximum modularity is Q = 0.650173\n",
      "Louvain completed 22 runs in 0.09139204025268555 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.5120761394500732 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.027146100997924805 seconds\n",
      "Jaccard graph constructed in 1.2636265754699707 seconds\n",
      "Wrote graph to binary file in 0.0019981861114501953 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.747293\n",
      "After 2 runs, maximum modularity is Q = 0.749494\n",
      "Louvain completed 22 runs in 0.08928799629211426 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.764256000518799 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.01790452003479004 seconds\n",
      "Jaccard graph constructed in 1.2467350959777832 seconds\n",
      "Wrote graph to binary file in 0.001634836196899414 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.64413\n",
      "After 2 runs, maximum modularity is Q = 0.647285\n",
      "After 4 runs, maximum modularity is Q = 0.648501\n",
      "Louvain completed 24 runs in 0.10558795928955078 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.5749380588531494 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.017065048217773438 seconds\n",
      "Jaccard graph constructed in 1.2830278873443604 seconds\n",
      "Wrote graph to binary file in 0.0016684532165527344 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.766478\n",
      "Louvain completed 21 runs in 0.0744330883026123 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.5989797115325928 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving embedding: 97it [00:30,  3.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell map untreated\n",
    "\n",
    "from cellmaps_coembedding.runner import MuseCoEmbeddingGenerator\n",
    "from cellmaps_coembedding.runner import CellmapsCoEmbedder\n",
    "\n",
    "ppi_embeddingdir = '2.ppi_embedding'\n",
    "image_embeddingdir = 'embedding_old_green/untreated'\n",
    "outdir = '3_old_green.coembedding_untreated'\n",
    "gen = MuseCoEmbeddingGenerator(ppi_embeddingdir=ppi_embeddingdir,\n",
    "                               image_embeddingdir=image_embeddingdir,\n",
    "                               outdir=os.path.abspath(outdir))\n",
    "\n",
    "x = CellmapsCoEmbedder(outdir=outdir,\n",
    "                      inputdirs=[ppi_embeddingdir, image_embeddingdir],\n",
    "                      embedding_generator=gen)\n",
    "x.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a94fac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "input_file = \"embedding_old_green/untreated/image_emd.tsv\"\n",
    "# Store embeddings per gene\n",
    "data = defaultdict(list)\n",
    "# Read the original file\n",
    "with open(input_file, \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    header = next(reader) # store header\n",
    "    for row in reader:\n",
    "        gene_id = row[0]\n",
    "        embedding = list(map(float, row[1:]))\n",
    "        data[gene_id].append(embedding)\n",
    "# Compute mean and overwrite the same file\n",
    "with open(input_file, \"w\", newline='') as out:\n",
    "    writer = csv.writer(out, delimiter='\\t')\n",
    "    writer.writerow([\"id\"] + header[1:]) # write header back\n",
    "    for gene_id, vectors in data.items():\n",
    "        arr = np.array(vectors)\n",
    "        mean_vector = np.mean(arr, axis=0)\n",
    "        writer.writerow([gene_id] + mean_vector.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7e69678c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique genes: 461\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "input_file = \"embedding_old_green/untreated/image_emd.tsv\"\n",
    "unique_genes = set()\n",
    "with open(input_file, \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    next(reader) # skip header\n",
    "    for row in reader:\n",
    "        gene_id = row[0]\n",
    "        unique_genes.add(gene_id)\n",
    "print(f\"Number of unique genes: {len(unique_genes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8d8887ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating hierarchy: 15it [00:00, 85.55it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hnguye24/.conda/envs/yolo7/lib/python3.10/site-packages/cellmaps_generate_hierarchy/runner.py:623: UserWarning: Layout disabled due to incompatibilities with HCX format\n",
      "  warnings.warn(\"Layout disabled due to incompatibilities with HCX format\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cellmaps_generate_hierarchy.ppi import CosineSimilarityPPIGenerator\n",
    "from cellmaps_generate_hierarchy.hierarchy import CDAPSHiDeFHierarchyGenerator\n",
    "from cellmaps_generate_hierarchy.maturehierarchy import HiDeFHierarchyRefiner\n",
    "from cellmaps_generate_hierarchy.hcx import HCXFromCDAPSCXHierarchy\n",
    "from cellmaps_generate_hierarchy.runner import CellmapsGenerateHierarchy\n",
    "\n",
    "inputdir = '3_old_green.coembedding_untreated'\n",
    "outdir = '5.2_old_green_hierarchy_untreated'\n",
    "ppigen = CosineSimilarityPPIGenerator(embeddingdirs=[inputdir])\n",
    "\n",
    "refiner = HiDeFHierarchyRefiner()\n",
    "\n",
    "converter = HCXFromCDAPSCXHierarchy()\n",
    "\n",
    "hiergen = CDAPSHiDeFHierarchyGenerator(refiner=refiner,\n",
    "                                       hcxconverter=converter)\n",
    "\n",
    "x = CellmapsGenerateHierarchy(outdir=outdir,\n",
    "                              inputdirs=inputdir,\n",
    "                              ppigen=ppigen,\n",
    "                              hiergen=hiergen)\n",
    "x.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "82d164eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent network UUID is 6205f09e-9121-11f0-a218-005056ae3c32 and its URL in NDEx is https://www.ndexbio.org/viewer/networks/6205f09e-9121-11f0-a218-005056ae3c32\n",
      "Hierarchy network UUID is 62218ef0-9121-11f0-a218-005056ae3c32 and its URL in NDEx is https://www.ndexbio.org/viewer/networks/62218ef0-9121-11f0-a218-005056ae3c32\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ndex2\n",
    "from ndex2.cx2 import RawCX2NetworkFactory\n",
    "from cellmaps_generate_hierarchy.ndexupload import NDExHierarchyUploader\n",
    "\n",
    "#Specify NDEx server\n",
    "ndexserver = 'public.ndexbio.org'\n",
    "ndexuser = ''\n",
    "ndexpassword = ''\n",
    "    \n",
    "# Specify paths to hierarchy and its parent (you can find example files in examples directory in cellmaps_generate_hierarchy_repo)\n",
    "hierarchy_path = './5.2_old_green_hierarchy_untreated/hierarchy.cx2'\n",
    "parent_network_path = './5.2_old_green_hierarchy_untreated/hierarchy_parent.cx2'\n",
    "\n",
    "# Load the hierarchy and parent network CX2 files into network objects\n",
    "factory = RawCX2NetworkFactory()\n",
    "hierarchy_network = factory.get_cx2network(hierarchy_path)\n",
    "parent_network = factory.get_cx2network(parent_network_path)\n",
    "\n",
    "# Initialize NDExHierarchyUploader with the specified NDEx server and credentials\n",
    "uploader = NDExHierarchyUploader(ndexserver, ndexuser, ndexpassword, visibility=True)\n",
    "\n",
    "# Upload the hierarchy and parent network to NDEx\n",
    "parent_uuid, parenturl, hierarchy_uuid, hierarchyurl = uploader.save_hierarchy_and_parent_network(hierarchy_network, parent_network)\n",
    "\n",
    "print(f\"Parent network UUID is {parent_uuid} and its URL in NDEx is {parenturl}\")\n",
    "print(f\"Hierarchy network UUID is {hierarchy_uuid} and its URL in NDEx is {hierarchyurl}\")\n",
    "\n",
    "# # Another option is to just specify the directory where the files are placed\n",
    "# _, _, _, hierarchyurl = uploader.upload_hierary_and_parent_network_from_files('./examples/')\n",
    "# print(f'Hierarchy uploaded. To view the hierarchy, paste this URL in your browser: {hierarchyurl}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "60d6403f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean values saved to: embedding_old_green/paclitaxel/gene_means.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load TSV file\n",
    "input_file = \"embedding_old_green/paclitaxel/image_emd.tsv\"   # replace with your filename\n",
    "df = pd.read_csv(input_file, sep=\"\\t\")\n",
    "\n",
    "# Step 2: Compute mean per gene (assumes first column is \"id\" or \"Gene\")\n",
    "mean_df = df.groupby(df.columns[0]).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Step 3: Save to a new file\n",
    "output_file = \"embedding_old_green/paclitaxel/gene_means.tsv\"\n",
    "mean_df.to_csv(output_file, sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"Mean values saved to:\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c3b130fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files renamed successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Paths\n",
    "old_dir = \"embedding_old_green/paclitaxel\"\n",
    "old_image = os.path.join(old_dir, \"image_emd.tsv\")\n",
    "new_image = os.path.join(old_dir, \"image_emd2.tsv\")\n",
    "gene_means = os.path.join(old_dir, \"gene_means.tsv\")\n",
    "new_gene_means = os.path.join(old_dir, \"image_emd.tsv\")\n",
    "\n",
    "# Rename image_emd.tsv ‚Üí image_emd2.tsv\n",
    "os.rename(old_image, new_image)\n",
    "\n",
    "# Rename gene_means.tsv ‚Üí image_emd.tsv\n",
    "os.rename(gene_means, new_gene_means)\n",
    "\n",
    "print(\"Files renamed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2b688cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving embedding: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.04577040672302246 seconds\n",
      "Jaccard graph constructed in 1.2841176986694336 seconds\n",
      "Wrote graph to binary file in 0.0017898082733154297 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.664183\n",
      "After 3 runs, maximum modularity is Q = 0.66654\n",
      "After 8 runs, maximum modularity is Q = 0.667759\n",
      "Louvain completed 28 runs in 0.11507487297058105 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.7138445377349854 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.016773223876953125 seconds\n",
      "Jaccard graph constructed in 1.263922929763794 seconds\n",
      "Wrote graph to binary file in 0.0016999244689941406 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.661529\n",
      "After 2 runs, maximum modularity is Q = 0.663141\n",
      "After 5 runs, maximum modularity is Q = 0.664297\n",
      "Louvain completed 25 runs in 0.11255073547363281 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.653322458267212 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.03258371353149414 seconds\n",
      "Jaccard graph constructed in 1.3093757629394531 seconds\n",
      "Wrote graph to binary file in 0.0016644001007080078 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.515144\n",
      "Louvain completed 21 runs in 0.07598257064819336 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.659884452819824 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.017822742462158203 seconds\n",
      "Jaccard graph constructed in 1.418558120727539 seconds\n",
      "Wrote graph to binary file in 0.0038347244262695312 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.640284\n",
      "Louvain completed 21 runs in 0.07484698295593262 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.8094987869262695 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.02104496955871582 seconds\n",
      "Jaccard graph constructed in 1.3907802104949951 seconds\n",
      "Wrote graph to binary file in 0.004581451416015625 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.656833\n",
      "Louvain completed 21 runs in 0.07618141174316406 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.7486658096313477 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.019242048263549805 seconds\n",
      "Jaccard graph constructed in 1.4395077228546143 seconds\n",
      "Wrote graph to binary file in 0.0031998157501220703 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.744972\n",
      "After 17 runs, maximum modularity is Q = 0.746042\n",
      "Louvain completed 37 runs in 0.13056492805480957 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.860368490219116 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.017009258270263672 seconds\n",
      "Jaccard graph constructed in 1.2490670680999756 seconds\n",
      "Wrote graph to binary file in 0.0015883445739746094 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.647728\n",
      "After 4 runs, maximum modularity is Q = 0.650226\n",
      "Louvain completed 24 runs in 0.09523606300354004 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.60347318649292 seconds\n",
      "Finding 10 nearest neighbors using cosine metric and 'brute' algorithm\n",
      "Neighbors computed in 0.016089916229248047 seconds\n",
      "Jaccard graph constructed in 1.283724069595337 seconds\n",
      "Wrote graph to binary file in 0.0026581287384033203 seconds\n",
      "Running Louvain modularity optimization\n",
      "After 1 runs, maximum modularity is Q = 0.754072\n",
      "Louvain completed 21 runs in 0.07631468772888184 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 2.6187260150909424 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving embedding: 97it [00:31,  3.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell map vorinostat\n",
    "\n",
    "from cellmaps_coembedding.runner import MuseCoEmbeddingGenerator\n",
    "from cellmaps_coembedding.runner import CellmapsCoEmbedder\n",
    "\n",
    "ppi_embeddingdir = '2.ppi_embedding'\n",
    "image_embeddingdir = 'embedding_old_green/paclitaxel'\n",
    "outdir = '3_old_green.coembedding_paclitaxel'\n",
    "gen = MuseCoEmbeddingGenerator(ppi_embeddingdir=ppi_embeddingdir,\n",
    "                               image_embeddingdir=image_embeddingdir,\n",
    "                               outdir=os.path.abspath(outdir))\n",
    "\n",
    "x = CellmapsCoEmbedder(outdir=outdir,\n",
    "                      inputdirs=[ppi_embeddingdir, image_embeddingdir],\n",
    "                      embedding_generator=gen)\n",
    "x.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4869a36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "input_file = \"embedding_old_green/paclitaxel/image_emd.tsv\"\n",
    "# Store embeddings per gene\n",
    "data = defaultdict(list)\n",
    "# Read the original file\n",
    "with open(input_file, \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    header = next(reader) # store header\n",
    "    for row in reader:\n",
    "        gene_id = row[0]\n",
    "        embedding = list(map(float, row[1:]))\n",
    "        data[gene_id].append(embedding)\n",
    "# Compute mean and overwrite the same file\n",
    "with open(input_file, \"w\", newline='') as out:\n",
    "    writer = csv.writer(out, delimiter='\\t')\n",
    "    writer.writerow([\"id\"] + header[1:]) # write header back\n",
    "    for gene_id, vectors in data.items():\n",
    "        arr = np.array(vectors)\n",
    "        mean_vector = np.mean(arr, axis=0)\n",
    "        writer.writerow([gene_id] + mean_vector.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cfa386a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique genes: 461\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "input_file = \"embedding_old_green/paclitaxel/image_emd.tsv\"\n",
    "unique_genes = set()\n",
    "with open(input_file, \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    next(reader) # skip header\n",
    "    for row in reader:\n",
    "        gene_id = row[0]\n",
    "        unique_genes.add(gene_id)\n",
    "print(f\"Number of unique genes: {len(unique_genes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "727d5703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating hierarchy: 15it [00:00, 77.56it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n",
      "Generating CX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hnguye24/.conda/envs/yolo7/lib/python3.10/site-packages/cellmaps_generate_hierarchy/runner.py:623: UserWarning: Layout disabled due to incompatibilities with HCX format\n",
      "  warnings.warn(\"Layout disabled due to incompatibilities with HCX format\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cellmaps_generate_hierarchy.ppi import CosineSimilarityPPIGenerator\n",
    "from cellmaps_generate_hierarchy.hierarchy import CDAPSHiDeFHierarchyGenerator\n",
    "from cellmaps_generate_hierarchy.maturehierarchy import HiDeFHierarchyRefiner\n",
    "from cellmaps_generate_hierarchy.hcx import HCXFromCDAPSCXHierarchy\n",
    "from cellmaps_generate_hierarchy.runner import CellmapsGenerateHierarchy\n",
    "\n",
    "inputdir = '3_old_green.coembedding_paclitaxel'\n",
    "outdir = '5.2_old_green_hierarchy_paclitaxel'\n",
    "ppigen = CosineSimilarityPPIGenerator(embeddingdirs=[inputdir])\n",
    "\n",
    "refiner = HiDeFHierarchyRefiner()\n",
    "\n",
    "converter = HCXFromCDAPSCXHierarchy()\n",
    "\n",
    "hiergen = CDAPSHiDeFHierarchyGenerator(refiner=refiner,\n",
    "                                       hcxconverter=converter)\n",
    "\n",
    "x = CellmapsGenerateHierarchy(outdir=outdir,\n",
    "                              inputdirs=inputdir,\n",
    "                              ppigen=ppigen,\n",
    "                              hiergen=hiergen)\n",
    "x.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b413c328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent network UUID is 1e60ab92-9123-11f0-a218-005056ae3c32 and its URL in NDEx is https://www.ndexbio.org/viewer/networks/1e60ab92-9123-11f0-a218-005056ae3c32\n",
      "Hierarchy network UUID is 1e7c9804-9123-11f0-a218-005056ae3c32 and its URL in NDEx is https://www.ndexbio.org/viewer/networks/1e7c9804-9123-11f0-a218-005056ae3c32\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ndex2\n",
    "from ndex2.cx2 import RawCX2NetworkFactory\n",
    "from cellmaps_generate_hierarchy.ndexupload import NDExHierarchyUploader\n",
    "\n",
    "#Specify NDEx server\n",
    "ndexserver = 'public.ndexbio.org'\n",
    "ndexuser = ''\n",
    "ndexpassword = ''\n",
    "    \n",
    "# Specify paths to hierarchy and its parent (you can find example files in examples directory in cellmaps_generate_hierarchy_repo)\n",
    "hierarchy_path = './5.2_old_hierarchy_paclitaxel/hierarchy.cx2'\n",
    "parent_network_path = './5.2_old_hierarchy_paclitaxel/hierarchy_parent.cx2'\n",
    "\n",
    "# Load the hierarchy and parent network CX2 files into network objects\n",
    "factory = RawCX2NetworkFactory()\n",
    "hierarchy_network = factory.get_cx2network(hierarchy_path)\n",
    "parent_network = factory.get_cx2network(parent_network_path)\n",
    "\n",
    "# Initialize NDExHierarchyUploader with the specified NDEx server and credentials\n",
    "uploader = NDExHierarchyUploader(ndexserver, ndexuser, ndexpassword, visibility=True)\n",
    "\n",
    "# Upload the hierarchy and parent network to NDEx\n",
    "parent_uuid, parenturl, hierarchy_uuid, hierarchyurl = uploader.save_hierarchy_and_parent_network(hierarchy_network, parent_network)\n",
    "\n",
    "print(f\"Parent network UUID is {parent_uuid} and its URL in NDEx is {parenturl}\")\n",
    "print(f\"Hierarchy network UUID is {hierarchy_uuid} and its URL in NDEx is {hierarchyurl}\")\n",
    "\n",
    "# # Another option is to just specify the directory where the files are placed\n",
    "# _, _, _, hierarchyurl = uploader.upload_hierary_and_parent_network_from_files('./examples/')\n",
    "# print(f'Hierarchy uploaded. To view the hierarchy, paste this URL in your browser: {hierarchyurl}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ebba7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:.conda-yolo7]",
   "language": "python",
   "name": "conda-env-.conda-yolo7-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
